{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a4e3e55",
   "metadata": {},
   "source": [
    "# Analyse server stored data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2734784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "import time\n",
    "from collections import Counter\n",
    "import random\n",
    "\n",
    "from pymongo.mongo_client import MongoClient\n",
    "from pymongo.server_api import ServerApi\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.style\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from src.media import Outlet, Article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e402d4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions\n",
    "def getDateRange(start_date, end_date):  # Return list of datetime.date objects between start_date and end_date (inclusive).\n",
    "    date_list = []\n",
    "    curr_date = start_date\n",
    "    while curr_date <= end_date:\n",
    "        date_list.append(curr_date)\n",
    "        curr_date += timedelta(days=1)\n",
    "    return date_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6644714f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make maptlotlib show graphs in new window\n",
    "%matplotlib qt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2968257f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "# Date range for articles being scraped from the server\n",
    "startScrapeDate = \"01/02/2022\"\n",
    "endScrapeDate = \"05/10/2022\"\n",
    "\n",
    "collectionCap = -1 # The maximum amount of articles to get pulled from the server (set to -1 for uncaped scraping)\n",
    "\n",
    "startScrapeDate = datetime.strptime(startScrapeDate, \"%d/%m/%Y\")\n",
    "endScrapeDate = datetime.strptime(endScrapeDate, \"%d/%m/%Y\")\n",
    "stopwordsSet = set(stopwords.words('english'))\n",
    "exclusionList = [\"say\", \"new\", \"news\", \"day\", \"days\"]\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "plt.style.use('Solarize_Light2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c58a7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load setup data\n",
    "with open(\"./settings.json\", \"r\") as setupFile:\n",
    "    setupData = json.load(setupFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8591f4fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Collected article number 256775\n",
      " Collected a total of 256775 articles in 67.743 seconds\n"
     ]
    }
   ],
   "source": [
    "articleList = []\n",
    "startScanTime = time.time() # Track the time elapsed \n",
    "DBClient = MongoClient(setupData[\"DB_URI\"], server_api = ServerApi('1')) # Connect to the database\n",
    "\n",
    "# Get articles from DBClient\n",
    "articleCollection = DBClient[setupData[\"DB_NAME\"]]['newsData']\n",
    "articleCursor = articleCollection.aggregate([{'$match': {'publishDate': {\n",
    "                '$gt': startScrapeDate, \n",
    "                '$lt': endScrapeDate\n",
    "        }}}])\n",
    "\n",
    "for articleIndex, article in enumerate(articleCursor):\n",
    "    articleList.append(Article(\n",
    "                article[\"outletName\"],\n",
    "                article[\"headline\"],\n",
    "                article[\"description\"],\n",
    "                article[\"author\"],\n",
    "                article[\"publishDate\"],\n",
    "                article[\"sentimentScore\"]\n",
    "        ))\n",
    "    \n",
    "    print(f\"\\r Collected article number {articleIndex + 1}\", end=\"\")\n",
    "print(f\"\\n Collected a total of {len(articleList)} articles in {round((time.time() - startScanTime), 3)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1deb0684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28 outlets in total\n"
     ]
    }
   ],
   "source": [
    "# Sort articles by outlet\n",
    "outletList = []\n",
    "\n",
    "for articleIndex, article in enumerate(articleList):\n",
    "    foundOutlet = False # If the outlet has been found within `outletList`\n",
    "    for outlet in outletList:\n",
    "        if outlet.name == article.outlet:\n",
    "            outlet.addArticle(article)\n",
    "            foundOutlet = True\n",
    "            break\n",
    "    if not foundOutlet: # Make new outlet\n",
    "        newOutlet = Outlet(article.outlet)\n",
    "        outletList.append(newOutlet)    \n",
    "print(f\"Found {len(outletList)} outlets in total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45e1f138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ABC News ===\n",
      "Published a total of 12301 articles\n",
      "Has an average sentiment of -0.092\n",
      "\n",
      "\n",
      "=== 9 News ===\n",
      "Published a total of 5721 articles\n",
      "Has an average sentiment of -0.179\n",
      "\n",
      "\n",
      "=== Sydney Morning Herald ===\n",
      "Published a total of 14723 articles\n",
      "Has an average sentiment of -0.044\n",
      "\n",
      "\n",
      "=== SBS Australia ===\n",
      "Published a total of 308 articles\n",
      "Has an average sentiment of -0.09\n",
      "\n",
      "\n",
      "=== Independent Australia ===\n",
      "Published a total of 795 articles\n",
      "Has an average sentiment of -0.091\n",
      "\n",
      "\n",
      "=== Daily Telegraph ===\n",
      "Published a total of 2506 articles\n",
      "Has an average sentiment of -0.096\n",
      "\n",
      "\n",
      "=== The Age ===\n",
      "Published a total of 14666 articles\n",
      "Has an average sentiment of -0.044\n",
      "\n",
      "\n",
      "=== Michael West ===\n",
      "Published a total of 1182 articles\n",
      "Has an average sentiment of -0.01\n",
      "\n",
      "\n",
      "=== The Guardian ===\n",
      "Published a total of 28031 articles\n",
      "Has an average sentiment of -0.07\n",
      "\n",
      "\n",
      "=== Crikey ===\n",
      "Published a total of 2812 articles\n",
      "Has an average sentiment of -0.041\n",
      "\n",
      "\n",
      "=== CNN ===\n",
      "Published a total of 14824 articles\n",
      "Has an average sentiment of -0.1\n",
      "\n",
      "\n",
      "=== New York Times ===\n",
      "Published a total of 6129 articles\n",
      "Has an average sentiment of -0.157\n",
      "\n",
      "\n",
      "=== Fox News ===\n",
      "Published a total of 9163 articles\n",
      "Has an average sentiment of -0.123\n",
      "\n",
      "\n",
      "=== BBC News ===\n",
      "Published a total of 5337 articles\n",
      "Has an average sentiment of -0.225\n",
      "\n",
      "\n",
      "=== The Conversation ===\n",
      "Published a total of 2874 articles\n",
      "Has an average sentiment of 0.008\n",
      "\n",
      "\n",
      "=== The Washington Post ===\n",
      "Published a total of 4587 articles\n",
      "Has an average sentiment of -0.22\n",
      "\n",
      "\n",
      "=== Wall Street Journal ===\n",
      "Published a total of 1554 articles\n",
      "Has an average sentiment of -0.161\n",
      "\n",
      "\n",
      "=== CNBC ===\n",
      "Published a total of 4444 articles\n",
      "Has an average sentiment of -0.048\n",
      "\n",
      "\n",
      "=== Daily Mail ===\n",
      "Published a total of 43892 articles\n",
      "Has an average sentiment of -0.194\n",
      "\n",
      "\n",
      "=== Huffington Post ===\n",
      "Published a total of 11608 articles\n",
      "Has an average sentiment of -0.082\n",
      "\n",
      "\n",
      "=== BuzzFeed ===\n",
      "Published a total of 16154 articles\n",
      "Has an average sentiment of 0.11\n",
      "\n",
      "\n",
      "=== Amercian ABC ===\n",
      "Published a total of 5611 articles\n",
      "Has an average sentiment of -0.187\n",
      "\n",
      "\n",
      "=== The Economist ===\n",
      "Published a total of 2 articles\n",
      "Has an average sentiment of 0.0\n",
      "\n",
      "\n",
      "=== Sky News ===\n",
      "Published a total of 2582 articles\n",
      "Has an average sentiment of -0.246\n",
      "\n",
      "\n",
      "=== CBS News ===\n",
      "Published a total of 14750 articles\n",
      "Has an average sentiment of -0.075\n",
      "\n",
      "\n",
      "=== Alja Zeera ===\n",
      "Published a total of 8485 articles\n",
      "Has an average sentiment of -0.169\n",
      "\n",
      "\n",
      "=== USA Today ===\n",
      "Published a total of 7622 articles\n",
      "Has an average sentiment of -0.081\n",
      "\n",
      "\n",
      "=== South China Morning Post ===\n",
      "Published a total of 14084 articles\n",
      "Has an average sentiment of -0.12\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Text outputs for each outlet\n",
    "for outlet in outletList:\n",
    "    # Get the average sentiment\n",
    "    avgSentiment = sum(list(article.sentimentScore for article in outlet.articleList)) / len(outlet.articleList)\n",
    "    avgSentiment = avgSentiment \n",
    "        \n",
    "    print(f\"{'=' * 3} {outlet.name} {'=' * 3}\")\n",
    "    print(f\"Published a total of {len(outlet.articleList)} articles\")\n",
    "    print(f\"Has an average sentiment of {round(avgSentiment, 3)}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b796a9f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 10 most prolific journalists are:\n",
      "- None - 136663 | ['ABC News', 'CNN', 'Fox News', 'BBC News', 'The Conversation', 'Wall Street Journal', 'CNBC', 'Daily Mail', 'Huffington Post', 'BuzzFeed', 'Amercian ABC', 'The Economist', 'Sky News', 'CBS News', 'Alja Zeera', 'New York Times', 'The Washington Post']\n",
      "-  - 11861 | ['Sydney Morning Herald', 'Daily Telegraph', 'The Age', 'The Guardian', 'South China Morning Post']\n",
      "- 9News - 5722 | ['9 News']\n",
      "- Associated Press - 2170 | ['The Guardian', 'The Washington Post', 'South China Morning Post', 'USA Today']\n",
      "- Reuters - 1784 | ['The Guardian', 'South China Morning Post', 'New York Times', 'Crikey', 'Sydney Morning Herald', 'The Age']\n",
      "- Agence France-Presse - 1371 | ['The Guardian', 'South China Morning Post']\n",
      "- None found - 1370 | ['Sydney Morning Herald', 'SBS Australia', 'Daily Telegraph', 'The Age', 'The Guardian']\n",
      "- Australian Associated Press - 915 | ['The Guardian']\n",
      "- Fox News Staff - 857 | ['Fox News']\n",
      "- AAP - 789 | ['Michael West', 'Crikey', 'The Guardian']\n"
     ]
    }
   ],
   "source": [
    "# Text outputs for each journalist\n",
    "journalistList = []\n",
    "journalistOutput = {}\n",
    "for article in articleList:\n",
    "    journalistList.append(article.author)\n",
    "    try:\n",
    "        if article.outlet not in journalistOutput[article.author]:\n",
    "           journalistOutput[article.author].append(article.outlet)\n",
    "        \n",
    "    except KeyError:\n",
    "        journalistOutput[article.author] = [article.outlet]\n",
    "\n",
    "print(f\"The 10 most prolific journalists are:\")\n",
    "for journalist in Counter(journalistList).most_common(10):\n",
    "    print(f\"- {journalist[0]} - {journalist[1]} | {journalistOutput[journalist[0]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a25483a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display parameters\n",
    "topicList = [[\"ukraine\", \"ukrainian\",\"kyiv\", \"crimea\", \"donbas\", \"invasion\", \"russia-ukraine\", \"russia\", \"russian\", \"moscow\", \"annex\"]] # Which topics to use (leave blank for all) (MUST BE LOWERCASE)\n",
    "showOutletsList = [] # Which outlets to be shown (leave blank for all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b2e9d031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect data to plot\n",
    "plotArticles = {} # Stores the articles by the topic \n",
    "if topicList == []:\n",
    "    plotArticles['total'] = [] # If there are no topic, total is used to show the total amt of articles\n",
    "    for article in articleList:\n",
    "        if article.outlet in showOutletsList or showOutletsList == []:\n",
    "            plotArticles['total'].append(article)\n",
    "else:            \n",
    "    for topic in topicList: \n",
    "        plotArticles[topic[0]] = [] # Each topic stores corresponding articles in a list\n",
    "        for article in articleList:\n",
    "            if article.outlet in showOutletsList or showOutletsList == []: # If the article is from the specified outlet\n",
    "                for word in article.headline.split(\" \"):\n",
    "                    if word.lower() in topic: # If a given word from the article is in the topic searchlist\n",
    "                        plotArticles[topic[0]].append(article)\n",
    "                        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2daff92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot daily average (or total output) for any attribute over time, as a total/avg of all outlets\n",
    "plotAttribute = \"sentimentScore\" # The article attribute to be avg'd and plotted over time (set to `publishCount` for daily TOTAL output)\n",
    "plotDates = getDateRange(startScrapeDate, endScrapeDate)\n",
    "\n",
    "for topic in plotArticles.keys():\n",
    "    plotData = {}\n",
    "    for dateIndex, date in enumerate(plotDates):\n",
    "        if dateIndex + 1 != len(plotDates):\n",
    "            plotData[date] = []\n",
    "    for article in plotArticles[topic]:\n",
    "        articleDate = article.date\n",
    "        if plotAttribute == \"publishCount\":\n",
    "            plotData[articleDate.replace(hour=0, minute=0, second=0)].append(1)\n",
    "        else:\n",
    "            plotData[articleDate.replace(hour=0, minute=0, second=0)].append(getattr(article, plotAttribute))\n",
    "    \n",
    "    # Plot the data\n",
    "    xVals = list(plotData.keys())\n",
    "    yVals = []\n",
    "    for val in xVals:\n",
    "        try:\n",
    "            if plotAttribute == \"publishCount\":\n",
    "                yVals.append(len(plotData[val]))\n",
    "            else:\n",
    "                yVals.append(sum(plotData[val]) / len(plotData[val]))\n",
    "        except ZeroDivisionError:\n",
    "            yVals.append(0)\n",
    "    if plotAttribute == \"publishCount\":\n",
    "        print(f\"In total, {sum(yVals)} articles got published about {topic}\")\n",
    "    plt.plot(xVals, yVals, label=topic)\n",
    "    \n",
    "plt.title(f\"{plotAttribute} over time\")\n",
    "plt.legend()\n",
    "plt.ylim((-1, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1ee6dc85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For ABC News the overall average for ukraine was -0.2124\n",
      "For 9 News the overall average for ukraine was -0.1888\n",
      "For Sydney Morning Herald the overall average for ukraine was -0.1692\n",
      "For SBS Australia the overall average for ukraine was -0.022\n",
      "For Independent Australia the overall average for ukraine was -0.0209\n",
      "For Daily Telegraph the overall average for ukraine was -0.0492\n",
      "For The Age the overall average for ukraine was -0.1689\n",
      "For Michael West the overall average for ukraine was -0.0187\n",
      "For The Guardian the overall average for ukraine was -0.3093\n",
      "For Crikey the overall average for ukraine was -0.106\n",
      "For CNN the overall average for ukraine was -0.1656\n",
      "For New York Times the overall average for ukraine was -0.1966\n",
      "For Fox News the overall average for ukraine was -0.1184\n",
      "For BBC News the overall average for ukraine was -0.3624\n",
      "For The Conversation the overall average for ukraine was -0.0492\n",
      "For The Washington Post the overall average for ukraine was -0.1535\n",
      "For Wall Street Journal the overall average for ukraine was -0.2042\n",
      "For CNBC the overall average for ukraine was -0.1428\n",
      "For Daily Mail the overall average for ukraine was -0.2308\n",
      "For Huffington Post the overall average for ukraine was -0.1548\n",
      "For BuzzFeed the overall average for ukraine was -0.0219\n",
      "For Amercian ABC the overall average for ukraine was -0.1242\n",
      "For The Economist the overall average for ukraine was 0.0\n",
      "For Sky News the overall average for ukraine was -0.2302\n",
      "For CBS News the overall average for ukraine was -0.1935\n",
      "For Alja Zeera the overall average for ukraine was -0.1939\n",
      "For USA Today the overall average for ukraine was -0.2316\n",
      "For South China Morning Post the overall average for ukraine was -0.2917\n"
     ]
    }
   ],
   "source": [
    "# Plot any attribute over time but broken down by outlet\n",
    "plotAttribute = \"sentimentScore\" # The article attribute to be avg'd and plotted over time (set to `publishCount` for daily TOTAL output)\n",
    "plotDates = getDateRange(startScrapeDate, endScrapeDate) # A list of all the dates that will be plotted\n",
    "\n",
    "displayOutlets = [] # The list that keeps track of which outlets to display\n",
    "if showOutletsList == []: # If the user has not specified which outlets to show, show all of them\n",
    "    for outlet in outletList:\n",
    "        displayOutlets.append(outlet.name) \n",
    "else:\n",
    "    displayOutlets = showOutletsList # Else show only those specified\n",
    "\n",
    "for topic in plotArticles.keys():\n",
    "    for outlet in displayOutlets: # Show how each media outlet reports each topic\n",
    "        plotData = {} # Dict containing each display date as key, and the list of scores for that day as value\n",
    "        for dateIndex, date in enumerate(plotDates):\n",
    "            if dateIndex + 1 != len(plotDates):\n",
    "                plotData[date] = []\n",
    "                \n",
    "        for article in plotArticles[topic]:\n",
    "            if article.outlet == outlet:\n",
    "                articleDate = article.date\n",
    "                if plotAttribute == \"publishCount\": # If the user is trying to find how many articles have been published on a given day, add 1 per article\n",
    "                    plotData[articleDate.replace(hour=0, minute=0, second=0)].append(1)\n",
    "                else:\n",
    "                    plotData[articleDate.replace(hour=0, minute=0, second=0)].append(getattr(article, plotAttribute)) # Append the score to the daily list\n",
    "        \n",
    "        # Plot the data\n",
    "        xVals = list(plotData.keys())\n",
    "        yVals = []\n",
    "        for val in xVals:\n",
    "            try:\n",
    "                if plotAttribute == \"publishCount\":\n",
    "                    yVals.append(len(plotData[val])) # Plot the daily count (total)\n",
    "                else:\n",
    "                    yVals.append(sum(plotData[val]) / len(plotData[val])) # plot the daily average \n",
    "            except ZeroDivisionError:\n",
    "                yVals.append(0) # If there are no datapoints for the day, display 0\n",
    "        plt.plot(xVals, yVals, label=f\"{outlet} - {topic}\")\n",
    "        \n",
    "        if plotAttribute == \"publishCount\":\n",
    "            print(f\"In total, {outlet} published {sum(yVals)} articles about {topic}\")\n",
    "        else:\n",
    "            print(f\"For {outlet} the overall average for {topic} was {round(sum(yVals) / len(yVals), 4)}\")\n",
    "plt.title(f\"{plotAttribute} Over time by Outlet\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bd2cbb24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic sentimentScore is not available, the possible topics are ['ukraine']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'sentimentScore'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [40]\u001b[0m, in \u001b[0;36m<cell line: 22>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dateIndex \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(plotDates):\n\u001b[0;32m     20\u001b[0m         datedKeywords[date] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m article \u001b[38;5;129;01min\u001b[39;00m \u001b[43mplotArticles\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdisplayTopic\u001b[49m\u001b[43m]\u001b[49m:\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m article\u001b[38;5;241m.\u001b[39moutlet \u001b[38;5;129;01min\u001b[39;00m showOutletsList \u001b[38;5;129;01mor\u001b[39;00m showOutletsList \u001b[38;5;241m==\u001b[39m []: \u001b[38;5;66;03m# If the article is from the specified outlet\u001b[39;00m\n\u001b[0;32m     24\u001b[0m         articleDate \u001b[38;5;241m=\u001b[39m article\u001b[38;5;241m.\u001b[39mdate\n",
      "\u001b[1;31mKeyError\u001b[0m: 'sentimentScore'"
     ]
    }
   ],
   "source": [
    "# Find keywords for each day by topic\n",
    "dailyDisplay = 4 # The number of keywords that gets displayed for each date\n",
    "displayTopic = \"ukraine\" # The topic that gets graphed\n",
    "minTextScore = 2 # The minimum number of a times a keyword needs to be mentioned in order to get it's text displayed\n",
    "\n",
    "\n",
    "try:\n",
    "    plotArticles[displayTopic]\n",
    "except KeyError:\n",
    "    print(f\"Topic {displayTopic} is not available, the possible topics are {list(plotArticles.keys())}\")\n",
    "    \n",
    "\n",
    "keywordColors = {} # Dict containing the color for each keyword\n",
    "plotDates = getDateRange(startScrapeDate, endScrapeDate) # A list of all the dates that will be plotted\n",
    "totalKeywords = [] # All the keywords and their freqency\n",
    "\n",
    "datedKeywords = {} # A dict containg all the keywords in articles from a given date about the topic\n",
    "for dateIndex, date in enumerate(plotDates):\n",
    "    if dateIndex + 1 != len(plotDates):\n",
    "        datedKeywords[date] = []\n",
    "\n",
    "for article in plotArticles[displayTopic]:\n",
    "    if article.outlet in showOutletsList or showOutletsList == []: # If the article is from the specified outlet\n",
    "        articleDate = article.date\n",
    "        for word in article.headline.split(\" \"):\n",
    "            word = word.strip().lower()\n",
    "            if word not in stopwordsSet and len(word) > 2 and word not in exclusionList:\n",
    "                datedKeywords[articleDate.replace(hour=0, minute=0, second=0)].append(lemmatizer.lemmatize(word)) # Append the (lemmatized) word to the dict for the given date\n",
    "lastKeywords = []\n",
    "for date in datedKeywords.keys():\n",
    "    keywords = Counter(datedKeywords[date]).most_common(dailyDisplay)\n",
    "    for keyword in keywords:\n",
    "        try:\n",
    "            keywordColor = keywordColors[keyword[0]] # If the keyword already has a color for itself\n",
    "        except KeyError:\n",
    "            r = lambda: random.randint(0,255) # Else, generate a new color for the keyword\n",
    "            keywordColor = '#%02X%02X%02X' % (r(),r(),r())\n",
    "            keywordColors[keyword[0]] = keywordColor # If this is the first time \n",
    "\n",
    "        totalKeywords.append(keyword[0])\n",
    "        plt.scatter(date, keyword[1], color=keywordColor, label=keyword[0]) # Put the point on the graph\n",
    "\n",
    "        # Draw lines between points with the same keyword\n",
    "        foundPrior = False # Tracks whether the date before contains the same keyword\n",
    "        for lastKeyword in lastKeywords:\n",
    "            if lastKeyword[0] == keyword[0]:\n",
    "                plt.plot([lastDate, date], [lastKeyword[1], keyword[1]], color=keywordColor)\n",
    "                foundPrior = True\n",
    "                break\n",
    "\n",
    "        if not foundPrior and keyword[1] >= minTextScore: # Only display text if the point is at the start of a 'chain'\n",
    "            plt.text(date, keyword[1], keyword[0])\n",
    "\n",
    "    # Save the last date and keywords to plot lines in the next date\n",
    "    lastDate = date \n",
    "    lastKeywords = keywords\n",
    "\n",
    "print(f\"The most common keywords for {displayTopic} were\")\n",
    "for keyword, keyFreq in Counter(totalKeywords).most_common(15):\n",
    "    print(f\"- {keyword} - {keyFreq}\")\n",
    "    \n",
    "plt.title(f\"Keywords over time for topic {displayTopic}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "28e06e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a histogram for the number of articles with each sentiment scoresentimentData\n",
    "displayTopic = \"ukraine\" # The topic that gets graphed\n",
    "incrementCount = 50\n",
    "\n",
    "try:\n",
    "    plotArticles[displayTopic]\n",
    "except KeyError:\n",
    "    print(f\"Topic {displayTopic} is not available, the possible topics are {list(plotArticles.keys())}\")\n",
    "    \n",
    "sentimentData = []\n",
    "for article in plotArticles[displayTopic]:\n",
    "    sentimentData.append(article.sentimentScore)\n",
    "    \n",
    "plt.hist(sentimentData, incrementCount)\n",
    "plt.title(f\"Number of articles with each sentiment for topic {displayTopic}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fb3a39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
