{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a4e3e55",
   "metadata": {},
   "source": [
    "# Analyse server stored data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2734784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "import time\n",
    "from collections import Counter\n",
    "import random\n",
    "\n",
    "from pymongo.mongo_client import MongoClient\n",
    "from pymongo.server_api import ServerApi\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.style\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "import operator\n",
    "\n",
    "from src.media import Outlet, Article\n",
    "from src.data import getNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e402d4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions\n",
    "def getDateRange(start_date, end_date):  # Return list of datetime.date objects between start_date and end_date (inclusive).\n",
    "    date_list = []\n",
    "    curr_date = start_date\n",
    "    while curr_date <= end_date:\n",
    "        date_list.append(curr_date)\n",
    "        curr_date += timedelta(days=1)\n",
    "    return date_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6644714f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make maptlotlib show graphs in new window\n",
    "%matplotlib qt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2968257f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "# Date range for articles being scraped from the server\n",
    "startScrapeDate = \"01/08/2022\"\n",
    "endScrapeDate = \"31/12/2022\"\n",
    "\n",
    "collectionCap = -1 # The maximum amount of articles to get pulled from the server (set to -1 for uncaped scraping)\n",
    "\n",
    "startScrapeDate = datetime.strptime(startScrapeDate, \"%d/%m/%Y\")\n",
    "endScrapeDate = datetime.strptime(endScrapeDate, \"%d/%m/%Y\")\n",
    "stopwordsSet = set(stopwords.words('english'))\n",
    "exclusionList = [\"say\", \"new\", \"news\", \"day\", \"days\"]\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "plt.style.use('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c58a7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load setup data\n",
    "with open(\"./settings.json\", \"r\") as setupFile:\n",
    "    setupData = json.load(setupFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8591f4fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Collected article number 171713\n",
      " Collected a total of 171713 articles in 48.259 seconds\n"
     ]
    }
   ],
   "source": [
    "articleList = []\n",
    "startScanTime = time.time() # Track the time elapsed \n",
    "DBClient = MongoClient(setupData[\"DB_URI\"], server_api = ServerApi('1')) # Connect to the database\n",
    "\n",
    "# Get articles from DBClient\n",
    "articleCollection = DBClient[setupData[\"DB_NAME\"]]['newsData']\n",
    "articleCursor = articleCollection.aggregate([{'$match': {'publishDate': {\n",
    "                '$gt': startScrapeDate, \n",
    "                '$lt': endScrapeDate\n",
    "        }}}])\n",
    "\n",
    "for articleIndex, article in enumerate(articleCursor):\n",
    "    articleList.append(Article(\n",
    "                article[\"outletName\"],\n",
    "                article[\"headline\"],\n",
    "                article[\"description\"],\n",
    "                article[\"author\"],\n",
    "                article[\"publishDate\"],\n",
    "                article[\"sentimentScore\"]\n",
    "        ))\n",
    "    \n",
    "    print(f\"\\r Collected article number {articleIndex + 1}\", end=\"\")\n",
    "print(f\"\\n Collected a total of {len(articleList)} articles in {round((time.time() - startScanTime), 3)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1deb0684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 26 outlets in total\n"
     ]
    }
   ],
   "source": [
    "# Sort articles by outlet\n",
    "outletList = []\n",
    "\n",
    "for articleIndex, article in enumerate(articleList):\n",
    "    foundOutlet = False # If the outlet has been found within `outletList`\n",
    "    for outlet in outletList:\n",
    "        if outlet.name == article.outlet:\n",
    "            outlet.addArticle(article)\n",
    "            foundOutlet = True\n",
    "            break\n",
    "    if not foundOutlet: # Make new outlet\n",
    "        newOutlet = Outlet(article.outlet)\n",
    "        outletList.append(newOutlet)    \n",
    "print(f\"Found {len(outletList)} outlets in total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45e1f138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Daily Mail ===\n",
      "Published a total of 31734 articles\n",
      "Has an average sentiment of -0.206\n",
      "\n",
      "\n",
      "=== The Guardian ===\n",
      "Published a total of 18424 articles\n",
      "Has an average sentiment of -0.066\n",
      "\n",
      "\n",
      "=== CNN ===\n",
      "Published a total of 10848 articles\n",
      "Has an average sentiment of -0.092\n",
      "\n",
      "\n",
      "=== BuzzFeed ===\n",
      "Published a total of 10825 articles\n",
      "Has an average sentiment of 0.091\n",
      "\n",
      "\n",
      "=== South China Morning Post ===\n",
      "Published a total of 9894 articles\n",
      "Has an average sentiment of -0.092\n",
      "\n",
      "\n",
      "=== CBS News ===\n",
      "Published a total of 8561 articles\n",
      "Has an average sentiment of -0.054\n",
      "\n",
      "\n",
      "=== ABC News ===\n",
      "Published a total of 8488 articles\n",
      "Has an average sentiment of -0.112\n",
      "\n",
      "\n",
      "=== Huffington Post ===\n",
      "Published a total of 8007 articles\n",
      "Has an average sentiment of -0.067\n",
      "\n",
      "\n",
      "=== Sydney Morning Herald ===\n",
      "Published a total of 7537 articles\n",
      "Has an average sentiment of -0.073\n",
      "\n",
      "\n",
      "=== The Age ===\n",
      "Published a total of 7466 articles\n",
      "Has an average sentiment of -0.075\n",
      "\n",
      "\n",
      "=== Fox News ===\n",
      "Published a total of 7227 articles\n",
      "Has an average sentiment of -0.123\n",
      "\n",
      "\n",
      "=== Alja Zeera ===\n",
      "Published a total of 6395 articles\n",
      "Has an average sentiment of -0.128\n",
      "\n",
      "\n",
      "=== USA Today ===\n",
      "Published a total of 5452 articles\n",
      "Has an average sentiment of -0.066\n",
      "\n",
      "\n",
      "=== Amercian ABC ===\n",
      "Published a total of 4051 articles\n",
      "Has an average sentiment of -0.201\n",
      "\n",
      "\n",
      "=== BBC News ===\n",
      "Published a total of 3905 articles\n",
      "Has an average sentiment of -0.196\n",
      "\n",
      "\n",
      "=== New York Times ===\n",
      "Published a total of 3820 articles\n",
      "Has an average sentiment of -0.144\n",
      "\n",
      "\n",
      "=== 9 News ===\n",
      "Published a total of 3715 articles\n",
      "Has an average sentiment of -0.191\n",
      "\n",
      "\n",
      "=== CNBC ===\n",
      "Published a total of 2787 articles\n",
      "Has an average sentiment of -0.031\n",
      "\n",
      "\n",
      "=== Daily Telegraph ===\n",
      "Published a total of 2349 articles\n",
      "Has an average sentiment of -0.079\n",
      "\n",
      "\n",
      "=== Michael West ===\n",
      "Published a total of 1856 articles\n",
      "Has an average sentiment of -0.019\n",
      "\n",
      "\n",
      "=== The Conversation ===\n",
      "Published a total of 1821 articles\n",
      "Has an average sentiment of 0.006\n",
      "\n",
      "\n",
      "=== Sky News ===\n",
      "Published a total of 1820 articles\n",
      "Has an average sentiment of -0.232\n",
      "\n",
      "\n",
      "=== The Washington Post ===\n",
      "Published a total of 1773 articles\n",
      "Has an average sentiment of -0.209\n",
      "\n",
      "\n",
      "=== Crikey ===\n",
      "Published a total of 1326 articles\n",
      "Has an average sentiment of -0.064\n",
      "\n",
      "\n",
      "=== Wall Street Journal ===\n",
      "Published a total of 1141 articles\n",
      "Has an average sentiment of -0.149\n",
      "\n",
      "\n",
      "=== Independent Australia ===\n",
      "Published a total of 465 articles\n",
      "Has an average sentiment of -0.094\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "outletList.sort(key = lambda x : len(x.articleList), reverse=True)\n",
    "# Text outputs for each outlet\n",
    "for outlet in outletList:\n",
    "    # Get the average sentiment\n",
    "    avgSentiment = sum(list(article.sentimentScore for article in outlet.articleList)) / len(outlet.articleList)\n",
    "    avgSentiment = avgSentiment \n",
    "        \n",
    "    print(f\"{'=' * 3} {outlet.name} {'=' * 3}\")\n",
    "    print(f\"Published a total of {len(outlet.articleList)} articles\")\n",
    "    print(f\"Has an average sentiment of {round(avgSentiment, 3)}\")\n",
    "    print(\"\\n\")\n",
    "#     print(f\"{outlet.name},{len(outlet.articleList)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a25483a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display parameters\n",
    "topicList = [[\"mar-a-lago\",\"trump\",\"donald\",\"fbi\",\"raid\",\"seize\",\"documents\"]] # Which topics to use (leave blank for all) (MUST BE LOWERCASE)\n",
    "showOutletsList = [] # Which outlets to be shown (leave blank for all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2e9d031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect data to plot\n",
    "plotArticles = {} # Stores the articles by the topic \n",
    "if topicList == []:\n",
    "    plotArticles['total'] = [] # If there are no topic, total is used to show the total amt of articles\n",
    "    for article in articleList:\n",
    "        if article.outlet in showOutletsList or showOutletsList == []:\n",
    "            plotArticles['total'].append(article)\n",
    "else:            \n",
    "    for topic in topicList: \n",
    "        plotArticles[topic[0]] = [] # Each topic stores corresponding articles in a list\n",
    "        for article in articleList:\n",
    "            if article.outlet in showOutletsList or showOutletsList == []: # If the article is from the specified outlet\n",
    "                for word in article.headline.split(\" \"):\n",
    "                    if word.lower() in topic: # If a given word from the article is in the topic searchlist\n",
    "                        plotArticles[topic[0]].append(article)\n",
    "                        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2daff92f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average sentimentScore for mar-a-lago was -0.08557455468330036\n"
     ]
    }
   ],
   "source": [
    "# Plot daily average (or total output) for any attribute over time, as a total/avg of all outlets\n",
    "plotAttribute = \"sentimentScore\" # The article attribute to be avg'd and plotted over time (set to `publishCount` for daily TOTAL output)\n",
    "plotDates = getDateRange(startScrapeDate, endScrapeDate)\n",
    "\n",
    "for topic in plotArticles.keys():\n",
    "    plotData = {}\n",
    "    for dateIndex, date in enumerate(plotDates):\n",
    "        if dateIndex + 1 != len(plotDates):\n",
    "            plotData[date] = []\n",
    "    for article in plotArticles[topic]:\n",
    "        articleDate = article.date\n",
    "        if plotAttribute == \"publishCount\":\n",
    "            plotData[articleDate.replace(hour=0, minute=0, second=0)].append(1)\n",
    "        else:\n",
    "            plotData[articleDate.replace(hour=0, minute=0, second=0)].append(getattr(article, plotAttribute))\n",
    "    \n",
    "    # Plot the data\n",
    "    xVals = list(plotData.keys())\n",
    "    yVals = []\n",
    "    for val in xVals:\n",
    "        try:\n",
    "            if plotAttribute == \"publishCount\":\n",
    "                yVals.append(len(plotData[val]))\n",
    "            else:\n",
    "                yVals.append(sum(plotData[val]) / len(plotData[val]))\n",
    "        except ZeroDivisionError:\n",
    "            yVals.append(0)\n",
    "    if plotAttribute == \"publishCount\":\n",
    "        print(f\"In total, {sum(yVals)} articles got published about {topic}\")\n",
    "    else:\n",
    "        print(f\"The average {plotAttribute} for {topic} was {sum(yVals) / len(yVals)}\")\n",
    "    plt.plot(xVals, yVals, label=topic)\n",
    "    \n",
    "plt.title(f\"{plotAttribute} over time\")\n",
    "plt.legend()\n",
    "# plt.ylim((-1, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ee6dc85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Daily Mail the overall average for mar-a-lago was -0.1025\n",
      "For The Guardian the overall average for mar-a-lago was -0.0857\n",
      "For CNN the overall average for mar-a-lago was -0.0685\n",
      "For BuzzFeed the overall average for mar-a-lago was -0.014\n",
      "For South China Morning Post the overall average for mar-a-lago was -0.046\n",
      "For CBS News the overall average for mar-a-lago was -0.0046\n",
      "For ABC News the overall average for mar-a-lago was -0.0966\n",
      "For Huffington Post the overall average for mar-a-lago was -0.0676\n",
      "For Sydney Morning Herald the overall average for mar-a-lago was -0.0455\n",
      "For The Age the overall average for mar-a-lago was -0.0364\n",
      "For Fox News the overall average for mar-a-lago was -0.0757\n",
      "For Alja Zeera the overall average for mar-a-lago was -0.086\n",
      "For USA Today the overall average for mar-a-lago was -0.0428\n",
      "For Amercian ABC the overall average for mar-a-lago was -0.0676\n",
      "For BBC News the overall average for mar-a-lago was -0.0551\n",
      "For New York Times the overall average for mar-a-lago was -0.0146\n",
      "For 9 News the overall average for mar-a-lago was -0.0314\n",
      "For CNBC the overall average for mar-a-lago was -0.013\n",
      "For Daily Telegraph the overall average for mar-a-lago was -0.0033\n",
      "For Michael West the overall average for mar-a-lago was 0.0\n",
      "For The Conversation the overall average for mar-a-lago was -0.0007\n",
      "For Sky News the overall average for mar-a-lago was -0.041\n",
      "For The Washington Post the overall average for mar-a-lago was -0.0225\n",
      "For Crikey the overall average for mar-a-lago was 0.0011\n",
      "For Wall Street Journal the overall average for mar-a-lago was -0.0019\n",
      "For Independent Australia the overall average for mar-a-lago was -0.0047\n"
     ]
    }
   ],
   "source": [
    "# Plot any attribute over time but broken down by outlet\n",
    "plotAttribute = \"sentimentScore\" # The article attribute to be avg'd and plotted over time (set to `publishCount` for daily TOTAL output)\n",
    "plotDates = getDateRange(startScrapeDate, endScrapeDate) # A list of all the dates that will be plotted\n",
    "\n",
    "displayOutlets = [] # The list that keeps track of which outlets to display\n",
    "if showOutletsList == []: # If the user has not specified which outlets to show, show all of them\n",
    "    for outlet in outletList:\n",
    "        displayOutlets.append(outlet.name) \n",
    "else:\n",
    "    displayOutlets = showOutletsList # Else show only those specified\n",
    "\n",
    "for topic in plotArticles.keys():\n",
    "    for outlet in displayOutlets: # Show how each media outlet reports each topic\n",
    "        plotData = {} # Dict containing each display date as key, and the list of scores for that day as value\n",
    "        for dateIndex, date in enumerate(plotDates):\n",
    "            if dateIndex + 1 != len(plotDates):\n",
    "                plotData[date] = []\n",
    "                \n",
    "        for article in plotArticles[topic]:\n",
    "            if article.outlet == outlet:\n",
    "                articleDate = article.date\n",
    "                if plotAttribute == \"publishCount\": # If the user is trying to find how many articles have been published on a given day, add 1 per article\n",
    "                    plotData[articleDate.replace(hour=0, minute=0, second=0)].append(1)\n",
    "                else:\n",
    "                    plotData[articleDate.replace(hour=0, minute=0, second=0)].append(getattr(article, plotAttribute)) # Append the score to the daily list\n",
    "        \n",
    "        # Plot the data\n",
    "        xVals = list(plotData.keys())\n",
    "        yVals = []\n",
    "        for val in xVals:\n",
    "            try:\n",
    "                if plotAttribute == \"publishCount\":\n",
    "                    yVals.append(len(plotData[val])) # Plot the daily count (total)\n",
    "                else:\n",
    "                    yVals.append(sum(plotData[val]) / len(plotData[val])) # plot the daily average \n",
    "            except ZeroDivisionError:\n",
    "                yVals.append(0) # If there are no datapoints for the day, display 0\n",
    "        plt.plot(xVals, yVals, label=f\"{outlet} - {topic}\")\n",
    "        \n",
    "        if plotAttribute == \"publishCount\":\n",
    "#             print(f\"In total, {outlet} published {sum(yVals)} articles about {topic}\")\n",
    "            print(f\"{outlet},{sum(yVals)}\")\n",
    "        else:\n",
    "            print(f\"For {outlet} the overall average for {topic} was {round(sum(yVals) / len(yVals), 4)}\")\n",
    "plt.title(f\"{plotAttribute} Over time by Outlet\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d367042",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pos_tag' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m journalistOutput \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m article \u001b[38;5;129;01min\u001b[39;00m plotArticles[displayTopic]:\n\u001b[1;32m----> 6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mgetNames\u001b[49m\u001b[43m(\u001b[49m\u001b[43marticle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauthor\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      7\u001b[0m     journalistList\u001b[38;5;241m.\u001b[39mappend(article\u001b[38;5;241m.\u001b[39mauthor)\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\They-Speak-for-Us\\Tooling\\src\\data.py:25\u001b[0m, in \u001b[0;36mgetNames\u001b[1;34m(dataStr)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgetNames\u001b[39m(dataStr):\n\u001b[0;32m     24\u001b[0m     allowedPOS \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNNP\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNNS\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m---> 25\u001b[0m     taggedName \u001b[38;5;241m=\u001b[39m \u001b[43mpos_tag\u001b[49m(word_tokenize(dataStr))\n\u001b[0;32m     26\u001b[0m     totalName \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     27\u001b[0m     names \u001b[38;5;241m=\u001b[39m [] \u001b[38;5;66;03m# List containing each name present in the by-line\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pos_tag' is not defined"
     ]
    }
   ],
   "source": [
    "# Text outputs for each journalist by topic\n",
    "displayTopic = \"mar-a-lago\" # The topic that gets graphed\n",
    "journalistList = []\n",
    "journalistOutput = {}\n",
    "for article in plotArticles[displayTopic]:\n",
    "    print(getNames(article.author, pos_tag))\n",
    "    journalistList.append(article.author)\n",
    "    try:\n",
    "        if article.outlet not in journalistOutput[article.author]:\n",
    "           journalistOutput[article.author].append(article.outlet)\n",
    "        \n",
    "    except KeyError:\n",
    "        journalistOutput[article.author] = [article.outlet]\n",
    "\n",
    "print(f\"The 10 most prolific journalists are:\")\n",
    "for journalist in Counter(journalistList).most_common(1000):\n",
    "    print(f\"- {journalist[0]} - {journalist[1]} | {journalistOutput[journalist[0]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2cbb24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Find keywords for each day by topic\n",
    "dailyDisplay = 4 # The number of keywords that gets displayed for each date\n",
    "displayTopic = \"mar-a-lago\" # The topic that gets graphed\n",
    "minTextScore = 2 # The minimum number of a times a keyword needs to be mentioned in order to get it's text displayed\n",
    "\n",
    "\n",
    "try:\n",
    "    plotArticles[displayTopic]\n",
    "except KeyError:\n",
    "    print(f\"Topic {displayTopic} is not available, the possible topics are {list(plotArticles.keys())}\")\n",
    "    \n",
    "\n",
    "keywordColors = {} # Dict containing the color for each keyword\n",
    "plotDates = getDateRange(startScrapeDate, endScrapeDate) # A list of all the dates that will be plotted\n",
    "totalKeywords = [] # All the keywords and their freqency\n",
    "\n",
    "datedKeywords = {} # A dict containg all the keywords in articles from a given date about the topic\n",
    "for dateIndex, date in enumerate(plotDates):\n",
    "    if dateIndex + 1 != len(plotDates):\n",
    "        datedKeywords[date] = []\n",
    "\n",
    "for article in plotArticles[displayTopic]:\n",
    "    if article.outlet in showOutletsList or showOutletsList == []: # If the article is from the specified outlet\n",
    "        articleDate = article.date\n",
    "        for word in article.headline.split(\" \"):\n",
    "            word = word.strip().lower()\n",
    "            if word not in stopwordsSet and len(word) > 2 and word not in exclusionList:\n",
    "                datedKeywords[articleDate.replace(hour=0, minute=0, second=0)].append(lemmatizer.lemmatize(word)) # Append the (lemmatized) word to the dict for the given date\n",
    "lastKeywords = []\n",
    "for date in datedKeywords.keys():\n",
    "    keywords = Counter(datedKeywords[date]).most_common(dailyDisplay)\n",
    "    for keyword in keywords:\n",
    "        try:\n",
    "            keywordColor = keywordColors[keyword[0]] # If the keyword already has a color for itself\n",
    "        except KeyError:\n",
    "            r = lambda: random.randint(0,255) # Else, generate a new color for the keyword\n",
    "            keywordColor = '#%02X%02X%02X' % (r(),r(),r())\n",
    "            keywordColors[keyword[0]] = keywordColor # If this is the first time \n",
    "\n",
    "        totalKeywords.append(keyword[0])\n",
    "        plt.scatter(date, keyword[1], color=keywordColor, label=keyword[0]) # Put the point on the graph\n",
    "\n",
    "        # Draw lines between points with the same keyword\n",
    "        foundPrior = False # Tracks whether the date before contains the same keyword\n",
    "        for lastKeyword in lastKeywords:\n",
    "            if lastKeyword[0] == keyword[0]:\n",
    "                plt.plot([lastDate, date], [lastKeyword[1], keyword[1]], color=keywordColor)\n",
    "                foundPrior = True\n",
    "                break\n",
    "\n",
    "        if not foundPrior and keyword[1] >= minTextScore: # Only display text if the point is at the start of a 'chain'\n",
    "            plt.text(date, keyword[1], keyword[0])\n",
    "\n",
    "    # Save the last date and keywords to plot lines in the next date\n",
    "    lastDate = date \n",
    "    lastKeywords = keywords\n",
    "\n",
    "print(f\"The most common keywords for {displayTopic} were\")\n",
    "for keyword, keyFreq in Counter(totalKeywords).most_common(15):\n",
    "    print(f\"- {keyword} - {keyFreq}\")\n",
    "    \n",
    "plt.title(f\"Keywords over time for topic {displayTopic}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e06e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a histogram for the number of articles with each sentiment scores\n",
    "displayTopic = \"mar-a-lago\" # The topic that gets graphed\n",
    "incrementCount = 50\n",
    "\n",
    "try:\n",
    "    plotArticles[displayTopic]\n",
    "except KeyError:\n",
    "    print(f\"Topic {displayTopic} is not available, the possible topics are {list(plotArticles.keys())}\")\n",
    "    \n",
    "sentimentData = []\n",
    "for article in plotArticles[displayTopic]:\n",
    "    sentimentData.append(article.sentimentScore)\n",
    "    \n",
    "plt.hist(sentimentData, incrementCount)\n",
    "plt.title(f\"Number of articles with each sentiment for topic {displayTopic}\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0147d681",
   "metadata": {},
   "outputs": [],
   "source": [
    "displayTopic = \"mar-a-lago\"\n",
    "sentimentData = []\n",
    "for article in plotArticles[displayTopic]:\n",
    "    publishDate = article.date.replace(hour=0,minute=0,second=0)\n",
    "    if(str(publishDate) == \"2022-12-16 00:00:00\"):\n",
    "        sentimentData.append(article.sentimentScore)\n",
    "print(sum(sentimentData) / len(sentimentData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e603583",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
