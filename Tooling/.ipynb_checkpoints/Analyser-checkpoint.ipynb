{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a4e3e55",
   "metadata": {},
   "source": [
    "# Analyse server stored data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2734784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "import time\n",
    "from collections import Counter\n",
    "import random\n",
    "\n",
    "from pymongo.mongo_client import MongoClient\n",
    "from pymongo.server_api import ServerApi\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.style\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "import operator\n",
    "\n",
    "from src.media import Outlet, Article\n",
    "from src.data import getNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e402d4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions\n",
    "def getDateRange(start_date, end_date):  # Return list of datetime.date objects between start_date and end_date (inclusive).\n",
    "    date_list = []\n",
    "    curr_date = start_date\n",
    "    while curr_date <= end_date:\n",
    "        date_list.append(curr_date)\n",
    "        curr_date += timedelta(days=1)\n",
    "    return date_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6644714f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make maptlotlib show graphs in new window\n",
    "%matplotlib qt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2968257f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "# Date range for articles being scraped from the server\n",
    "startScrapeDate = \"01/03/2023\"\n",
    "endScrapeDate = \"26/03/2023\"\n",
    "\n",
    "collectionCap = -1 # The maximum amount of articles to get pulled from the server (set to -1 for uncaped scraping)\n",
    "\n",
    "startScrapeDate = datetime.strptime(startScrapeDate, \"%d/%m/%Y\")\n",
    "endScrapeDate = datetime.strptime(endScrapeDate, \"%d/%m/%Y\")\n",
    "stopwordsSet = set(stopwords.words('english'))\n",
    "exclusionList = [\"say\", \"new\", \"news\", \"day\", \"days\"]\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "plt.style.use('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1c58a7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load setup data\n",
    "with open(\"./settings.json\", \"r\") as setupFile:\n",
    "    setupData = json.load(setupFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8591f4fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Collected article number 30555\n",
      " Collected a total of 30555 articles in 11.896 seconds\n"
     ]
    }
   ],
   "source": [
    "articleList = []\n",
    "startScanTime = time.time() # Track the time elapsed \n",
    "DBClient = MongoClient(setupData[\"DB_URI\"], server_api = ServerApi('1')) # Connect to the database\n",
    "\n",
    "# Get articles from DBClient\n",
    "articleCollection = DBClient[setupData[\"DB_NAME\"]]['newsData']\n",
    "articleCursor = articleCollection.aggregate([{'$match': {'publishDate': {\n",
    "                '$gt': startScrapeDate, \n",
    "                '$lt': endScrapeDate\n",
    "        }}}])\n",
    "\n",
    "for articleIndex, article in enumerate(articleCursor):\n",
    "    articleList.append(Article(\n",
    "                article[\"outletName\"],\n",
    "                article[\"headline\"],\n",
    "                article[\"description\"],\n",
    "                article[\"author\"],\n",
    "                article[\"publishDate\"],\n",
    "                article[\"sentimentScore\"]\n",
    "        ))\n",
    "    \n",
    "    print(f\"\\r Collected article number {articleIndex + 1}\", end=\"\")\n",
    "print(f\"\\n Collected a total of {len(articleList)} articles in {round((time.time() - startScanTime), 3)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1deb0684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32 outlets in total\n"
     ]
    }
   ],
   "source": [
    "# Sort articles by outlet\n",
    "outletList = []\n",
    "\n",
    "for articleIndex, article in enumerate(articleList):\n",
    "    foundOutlet = False # If the outlet has been found within `outletList`\n",
    "    for outlet in outletList:\n",
    "        if outlet.name == article.outlet:\n",
    "            outlet.addArticle(article)\n",
    "            foundOutlet = True\n",
    "            break\n",
    "    if not foundOutlet: # Make new outlet\n",
    "        newOutlet = Outlet(article.outlet)\n",
    "        outletList.append(newOutlet)    \n",
    "print(f\"Found {len(outletList)} outlets in total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "45e1f138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Daily Mail ===\n",
      "Published a total of 5582 articles\n",
      "Has an average sentiment of -0.205\n",
      "\n",
      "\n",
      "=== The Guardian ===\n",
      "Published a total of 2985 articles\n",
      "Has an average sentiment of -0.066\n",
      "\n",
      "\n",
      "=== CNN ===\n",
      "Published a total of 1881 articles\n",
      "Has an average sentiment of -0.098\n",
      "\n",
      "\n",
      "=== BuzzFeed ===\n",
      "Published a total of 1834 articles\n",
      "Has an average sentiment of 0.085\n",
      "\n",
      "\n",
      "=== South China Morning Post ===\n",
      "Published a total of 1798 articles\n",
      "Has an average sentiment of -0.067\n",
      "\n",
      "\n",
      "=== CBS News ===\n",
      "Published a total of 1416 articles\n",
      "Has an average sentiment of -0.049\n",
      "\n",
      "\n",
      "=== ABC News ===\n",
      "Published a total of 1393 articles\n",
      "Has an average sentiment of -0.099\n",
      "\n",
      "\n",
      "=== Huffington Post ===\n",
      "Published a total of 1310 articles\n",
      "Has an average sentiment of -0.084\n",
      "\n",
      "\n",
      "=== Fox News ===\n",
      "Published a total of 1250 articles\n",
      "Has an average sentiment of -0.158\n",
      "\n",
      "\n",
      "=== The Age ===\n",
      "Published a total of 1134 articles\n",
      "Has an average sentiment of -0.048\n",
      "\n",
      "\n",
      "=== Sydney Morning Herald ===\n",
      "Published a total of 1119 articles\n",
      "Has an average sentiment of -0.056\n",
      "\n",
      "\n",
      "=== Alja Zeera ===\n",
      "Published a total of 1060 articles\n",
      "Has an average sentiment of -0.168\n",
      "\n",
      "\n",
      "=== USA Today ===\n",
      "Published a total of 1031 articles\n",
      "Has an average sentiment of -0.077\n",
      "\n",
      "\n",
      "=== The Washington Post ===\n",
      "Published a total of 710 articles\n",
      "Has an average sentiment of -0.23\n",
      "\n",
      "\n",
      "=== BBC News ===\n",
      "Published a total of 661 articles\n",
      "Has an average sentiment of -0.205\n",
      "\n",
      "\n",
      "=== Amercian ABC ===\n",
      "Published a total of 634 articles\n",
      "Has an average sentiment of -0.207\n",
      "\n",
      "\n",
      "=== 9 News ===\n",
      "Published a total of 602 articles\n",
      "Has an average sentiment of -0.175\n",
      "\n",
      "\n",
      "=== New York Times ===\n",
      "Published a total of 597 articles\n",
      "Has an average sentiment of -0.122\n",
      "\n",
      "\n",
      "=== CNBC ===\n",
      "Published a total of 501 articles\n",
      "Has an average sentiment of -0.003\n",
      "\n",
      "\n",
      "=== DW News ===\n",
      "Published a total of 475 articles\n",
      "Has an average sentiment of -0.061\n",
      "\n",
      "\n",
      "=== Michael West ===\n",
      "Published a total of 473 articles\n",
      "Has an average sentiment of -0.026\n",
      "\n",
      "\n",
      "=== Russia Today ===\n",
      "Published a total of 373 articles\n",
      "Has an average sentiment of -0.149\n",
      "\n",
      "\n",
      "=== Daily Telegraph ===\n",
      "Published a total of 315 articles\n",
      "Has an average sentiment of -0.068\n",
      "\n",
      "\n",
      "=== The Conversation ===\n",
      "Published a total of 298 articles\n",
      "Has an average sentiment of 0.003\n",
      "\n",
      "\n",
      "=== Sky News ===\n",
      "Published a total of 273 articles\n",
      "Has an average sentiment of -0.248\n",
      "\n",
      "\n",
      "=== Crikey ===\n",
      "Published a total of 184 articles\n",
      "Has an average sentiment of -0.05\n",
      "\n",
      "\n",
      "=== Islamic Republic News Agency ===\n",
      "Published a total of 184 articles\n",
      "Has an average sentiment of 0.087\n",
      "\n",
      "\n",
      "=== Al Arabiya ===\n",
      "Published a total of 171 articles\n",
      "Has an average sentiment of -0.078\n",
      "\n",
      "\n",
      "=== Tehran Times ===\n",
      "Published a total of 171 articles\n",
      "Has an average sentiment of 0.052\n",
      "\n",
      "\n",
      "=== Independent Australia ===\n",
      "Published a total of 83 articles\n",
      "Has an average sentiment of -0.119\n",
      "\n",
      "\n",
      "=== Reuters ===\n",
      "Published a total of 15 articles\n",
      "Has an average sentiment of 0.042\n",
      "\n",
      "\n",
      "=== Wall Street Journal ===\n",
      "Published a total of 10 articles\n",
      "Has an average sentiment of -0.057\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "outletList.sort(key = lambda x : len(x.articleList), reverse=True)\n",
    "# Text outputs for each outlet\n",
    "for outlet in outletList:\n",
    "    # Get the average sentiment\n",
    "    avgSentiment = sum(list(article.sentimentScore for article in outlet.articleList)) / len(outlet.articleList)\n",
    "    avgSentiment = avgSentiment \n",
    "        \n",
    "    print(f\"{'=' * 3} {outlet.name} {'=' * 3}\")\n",
    "    print(f\"Published a total of {len(outlet.articleList)} articles\")\n",
    "    print(f\"Has an average sentiment of {round(avgSentiment, 3)}\")\n",
    "    print(\"\\n\")\n",
    "#     print(f\"{outlet.name},{len(outlet.articleList)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a25483a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display parameters\n",
    "topicList = [] # Which topics to use (leave blank for all) (MUST BE LOWERCASE)\n",
    "showOutletsList = [\"Islamic Republic News Agency\"] # Which outlets to be shown (leave blank for all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b2e9d031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect data to plot\n",
    "plotArticles = {} # Stores the articles by the topic \n",
    "if topicList == []:\n",
    "    plotArticles['total'] = [] # If there are no topic, total is used to show the total amt of articles\n",
    "    for article in articleList:\n",
    "        if article.outlet in showOutletsList or showOutletsList == []:\n",
    "            plotArticles['total'].append(article)\n",
    "else:            \n",
    "    for topic in topicList: \n",
    "        plotArticles[topic[0]] = [] # Each topic stores corresponding articles in a list\n",
    "        for article in articleList:\n",
    "            if article.outlet in showOutletsList or showOutletsList == []: # If the article is from the specified outlet\n",
    "                for word in article.headline.split(\" \"):\n",
    "                    if word.lower() in topic: # If a given word from the article is in the topic searchlist\n",
    "                        plotArticles[topic[0]].append(article)\n",
    "                        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2daff92f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In total, 185 articles got published about total\n"
     ]
    }
   ],
   "source": [
    "# Plot daily average (or total output) for any attribute over time, as a total/avg of all outlets\n",
    "plotAttribute = \"publishCount\" # The article attribute to be avg'd and plotted over time (set to `publishCount` for daily TOTAL output)\n",
    "plotDates = getDateRange(startScrapeDate, endScrapeDate)\n",
    "\n",
    "for topic in plotArticles.keys():\n",
    "    plotData = {}\n",
    "    for dateIndex, date in enumerate(plotDates):\n",
    "        if dateIndex + 1 != len(plotDates):\n",
    "            plotData[date] = []\n",
    "    for article in plotArticles[topic]:\n",
    "        articleDate = article.date\n",
    "        if plotAttribute == \"publishCount\":\n",
    "            plotData[articleDate.replace(hour=0, minute=0, second=0)].append(1)\n",
    "        else:\n",
    "            plotData[articleDate.replace(hour=0, minute=0, second=0)].append(getattr(article, plotAttribute))\n",
    "    \n",
    "    # Plot the data\n",
    "    xVals = list(plotData.keys())\n",
    "    yVals = []\n",
    "    for val in xVals:\n",
    "        try:\n",
    "            if plotAttribute == \"publishCount\":\n",
    "                yVals.append(len(plotData[val]))\n",
    "            else:\n",
    "                yVals.append(sum(plotData[val]) / len(plotData[val]))\n",
    "        except ZeroDivisionError:\n",
    "            yVals.append(0)\n",
    "    if plotAttribute == \"publishCount\":\n",
    "        print(f\"In total, {sum(yVals)} articles got published about {topic}\")\n",
    "    else:\n",
    "        print(f\"The average {plotAttribute} for {topic} was {sum(yVals) / len(yVals)}\")\n",
    "    plt.plot(xVals, yVals, label=topic)\n",
    "    \n",
    "plt.title(f\"{plotAttribute} over time\")\n",
    "plt.legend()\n",
    "# plt.ylim((-1, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1ee6dc85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In total, Islamic Republic News Agency published 185 articles about total\n"
     ]
    }
   ],
   "source": [
    "# Plot any attribute over time but broken down by outlet\n",
    "plotAttribute = \"publishCount\" # The article attribute to be avg'd and plotted over time (set to `publishCount` for daily TOTAL output)\n",
    "plotDates = getDateRange(startScrapeDate, endScrapeDate) # A list of all the dates that will be plotted\n",
    "\n",
    "displayOutlets = [] # The list that keeps track of which outlets to display\n",
    "if showOutletsList == []: # If the user has not specified which outlets to show, show all of them\n",
    "    for outlet in outletList:\n",
    "        displayOutlets.append(outlet.name) \n",
    "else:\n",
    "    displayOutlets = showOutletsList # Else show only those specified\n",
    "\n",
    "for topic in plotArticles.keys():\n",
    "    for outlet in displayOutlets: # Show how each media outlet reports each topic\n",
    "        plotData = {} # Dict containing each display date as key, and the list of scores for that day as value\n",
    "        for dateIndex, date in enumerate(plotDates):\n",
    "            if dateIndex + 1 != len(plotDates):\n",
    "                plotData[date] = []\n",
    "                \n",
    "        for article in plotArticles[topic]:\n",
    "            if article.outlet == outlet:\n",
    "                articleDate = article.date\n",
    "                if plotAttribute == \"publishCount\": # If the user is trying to find how many articles have been published on a given day, add 1 per article\n",
    "                    plotData[articleDate.replace(hour=0, minute=0, second=0)].append(1)\n",
    "                else:\n",
    "                    plotData[articleDate.replace(hour=0, minute=0, second=0)].append(getattr(article, plotAttribute)) # Append the score to the daily list\n",
    "        \n",
    "        # Plot the data\n",
    "        xVals = list(plotData.keys())\n",
    "        yVals = []\n",
    "        for val in xVals:\n",
    "            try:\n",
    "                if plotAttribute == \"publishCount\":\n",
    "                    yVals.append(len(plotData[val])) # Plot the daily count (total)\n",
    "                else:\n",
    "                    yVals.append(sum(plotData[val]) / len(plotData[val])) # plot the daily average \n",
    "            except ZeroDivisionError:\n",
    "                yVals.append(0) # If there are no datapoints for the day, display 0\n",
    "        plt.plot(xVals, yVals, label=f\"{outlet} - {topic}\")\n",
    "        \n",
    "        if plotAttribute == \"publishCount\":\n",
    "            print(f\"In total, {outlet} published {sum(yVals)} articles about {topic}\")\n",
    "        else:\n",
    "            print(f\"For {outlet} the overall average for {topic} was {round(sum(yVals) / len(yVals), 4)}\")\n",
    "plt.title(f\"{plotAttribute} Over time by Outlet\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "41dc96b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 10 most prolific journalists are:\n",
      "- IRNA English - 185 | ['Islamic Republic News Agency']\n"
     ]
    }
   ],
   "source": [
    "# Text outputs for each journalist by topic\n",
    "displayTopic = \"total\" # The topic that gets graphed\n",
    "journalistList = []\n",
    "journalistOutput = {}\n",
    "for article in plotArticles[displayTopic]:\n",
    "    for name in getNames(str(article.author), pos_tag, word_tokenize):\n",
    "        journalistList.append(name)\n",
    "        try:\n",
    "            if article.outlet not in journalistOutput[name]:\n",
    "               journalistOutput[name].append(article.outlet)\n",
    "\n",
    "        except KeyError:\n",
    "            journalistOutput[name] = [article.outlet]\n",
    "\n",
    "print(f\"The 10 most prolific journalists are:\")\n",
    "for journalist in Counter(journalistList).most_common(1000):\n",
    "    print(f\"- {journalist[0]} - {journalist[1]} | {journalistOutput[journalist[0]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bd2cbb24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most common keywords for total were\n",
      "- iran - 12\n",
      "- iranian - 5\n",
      "- tie - 2\n",
      "- iran, - 2\n",
      "- official - 2\n",
      "- iran’s - 2\n",
      "- iran's - 2\n",
      "- belarus - 1\n",
      "- comprehensive - 1\n",
      "- improve - 1\n",
      "- iran: - 1\n",
      "- trade - 1\n",
      "- envoy - 1\n",
      "- uae - 1\n",
      "- trip - 1\n"
     ]
    }
   ],
   "source": [
    "# Find keywords for each day by topic\n",
    "dailyDisplay = 4 # The number of keywords that gets displayed for each date\n",
    "displayTopic = \"total\" # The topic that gets graphed\n",
    "minTextScore = 2 # The minimum number of a times a keyword needs to be mentioned in order to get it's text displayed\n",
    "\n",
    "\n",
    "try:\n",
    "    plotArticles[displayTopic]\n",
    "except KeyError:\n",
    "    print(f\"Topic {displayTopic} is not available, the possible topics are {list(plotArticles.keys())}\")\n",
    "    \n",
    "\n",
    "keywordColors = {} # Dict containing the color for each keyword\n",
    "plotDates = getDateRange(startScrapeDate, endScrapeDate) # A list of all the dates that will be plotted\n",
    "totalKeywords = [] # All the keywords and their freqency\n",
    "\n",
    "datedKeywords = {} # A dict containg all the keywords in articles from a given date about the topic\n",
    "for dateIndex, date in enumerate(plotDates):\n",
    "    if dateIndex + 1 != len(plotDates):\n",
    "        datedKeywords[date] = []\n",
    "\n",
    "for article in plotArticles[displayTopic]:\n",
    "    if article.outlet in showOutletsList or showOutletsList == []: # If the article is from the specified outlet\n",
    "        articleDate = article.date\n",
    "        for word in article.headline.split(\" \"):\n",
    "            word = word.strip().lower()\n",
    "            if word not in stopwordsSet and len(word) > 2 and word not in exclusionList:\n",
    "                datedKeywords[articleDate.replace(hour=0, minute=0, second=0)].append(lemmatizer.lemmatize(word)) # Append the (lemmatized) word to the dict for the given date\n",
    "lastKeywords = []\n",
    "for date in datedKeywords.keys():\n",
    "    keywords = Counter(datedKeywords[date]).most_common(dailyDisplay)\n",
    "    for keyword in keywords:\n",
    "        try:\n",
    "            keywordColor = keywordColors[keyword[0]] # If the keyword already has a color for itself\n",
    "        except KeyError:\n",
    "            r = lambda: random.randint(0,255) # Else, generate a new color for the keyword\n",
    "            keywordColor = '#%02X%02X%02X' % (r(),r(),r())\n",
    "            keywordColors[keyword[0]] = keywordColor # If this is the first time \n",
    "\n",
    "        totalKeywords.append(keyword[0])\n",
    "        plt.scatter(date, keyword[1], color=keywordColor, label=keyword[0]) # Put the point on the graph\n",
    "\n",
    "        # Draw lines between points with the same keyword\n",
    "        foundPrior = False # Tracks whether the date before contains the same keyword\n",
    "        for lastKeyword in lastKeywords:\n",
    "            if lastKeyword[0] == keyword[0]:\n",
    "                plt.plot([lastDate, date], [lastKeyword[1], keyword[1]], color=keywordColor)\n",
    "                foundPrior = True\n",
    "                break\n",
    "\n",
    "        if not foundPrior and keyword[1] >= minTextScore: # Only display text if the point is at the start of a 'chain'\n",
    "            plt.text(date, keyword[1], keyword[0])\n",
    "\n",
    "    # Save the last date and keywords to plot lines in the next date\n",
    "    lastDate = date \n",
    "    lastKeywords = keywords\n",
    "\n",
    "print(f\"The most common keywords for {displayTopic} were\")\n",
    "for keyword, keyFreq in Counter(totalKeywords).most_common(15):\n",
    "    print(f\"- {keyword} - {keyFreq}\")\n",
    "    \n",
    "plt.title(f\"Keywords over time for topic {displayTopic}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "28e06e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a histogram for the number of articles with each sentiment scores\n",
    "displayTopic = \"total\" # The topic that gets graphed\n",
    "incrementCount = 50\n",
    "\n",
    "try:\n",
    "    plotArticles[displayTopic]\n",
    "except KeyError:\n",
    "    print(f\"Topic {displayTopic} is not available, the possible topics are {list(plotArticles.keys())}\")\n",
    "    \n",
    "sentimentData = []\n",
    "for article in plotArticles[displayTopic]:\n",
    "    sentimentData.append(article.sentimentScore)\n",
    "    \n",
    "plt.hist(sentimentData, incrementCount)\n",
    "plt.title(f\"Number of articles with each sentiment for topic {displayTopic}\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c4b8e282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the most common verb, adjective and so on (NOTE, does not exclude stopwords)\n",
    "displayTopic = \"total\" # The topic that gets graphed\n",
    "words = []\n",
    "for article in plotArticles[\"total\"]:\n",
    "    for word in article.headline.split(\" \"):\n",
    "        words.append(word)\n",
    "wordCount = Counter(words).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b1ea1715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('in', 72),\n",
       " ('Iran', 61),\n",
       " ('to', 55),\n",
       " ('of', 49),\n",
       " ('Iranian', 26),\n",
       " ('on', 21),\n",
       " ('FM', 18),\n",
       " ('with', 17),\n",
       " ('for', 15),\n",
       " ('Iran,', 12),\n",
       " ('ties', 12),\n",
       " ('Nowruz', 12),\n",
       " ('Leader', 11),\n",
       " ('Iran’s', 11),\n",
       " (\"Iran's\", 11),\n",
       " ('Supreme', 10),\n",
       " ('at', 9),\n",
       " ('Iraq', 8),\n",
       " ('official', 7),\n",
       " ('Tehran', 7),\n",
       " ('UAE', 7),\n",
       " ('regional', 7),\n",
       " ('security', 6),\n",
       " ('Tehran-Riyadh', 6),\n",
       " ('agreement', 6),\n",
       " ('as', 6),\n",
       " ('New', 6),\n",
       " ('discuss', 6),\n",
       " ('Ramadan', 6),\n",
       " ('states', 5),\n",
       " ('Headlines', 5),\n",
       " ('English-language', 5),\n",
       " ('dailies', 5),\n",
       " ('March', 5),\n",
       " ('by', 5),\n",
       " ('talks', 5),\n",
       " ('trade', 5),\n",
       " ('Raisi', 5),\n",
       " ('attack', 5),\n",
       " ('Year', 5),\n",
       " ('welcomes', 4),\n",
       " ('Iran-Saudi', 4),\n",
       " ('says', 4),\n",
       " ('US', 4),\n",
       " ('be', 4),\n",
       " ('visit', 4),\n",
       " ('FMs', 4),\n",
       " ('president', 4),\n",
       " ('envoy', 4),\n",
       " ('speech', 4),\n",
       " ('new', 4),\n",
       " ('football', 4),\n",
       " ('growth', 4),\n",
       " ('condemns', 4),\n",
       " ('felicitates', 4),\n",
       " ('cooperation', 3),\n",
       " ('national', 3),\n",
       " ('economic', 3),\n",
       " ('Afghanistan', 3),\n",
       " ('Iran:', 3),\n",
       " ('not', 3),\n",
       " ('over', 3),\n",
       " ('top', 3),\n",
       " ('Envoy', 3),\n",
       " ('2023', 3),\n",
       " ('bilateral', 3),\n",
       " ('deliver', 3),\n",
       " ('Imam', 3),\n",
       " ('Reza', 3),\n",
       " ('Holy', 3),\n",
       " ('1st', 3),\n",
       " ('human', 3),\n",
       " ('rights', 3),\n",
       " ('Syrian', 3),\n",
       " ('part', 3),\n",
       " ('stability:', 3),\n",
       " ('Persian', 3),\n",
       " ('Saudi', 3),\n",
       " ('meets', 3),\n",
       " ('Islamic', 3),\n",
       " ('control,', 3),\n",
       " ('year', 3),\n",
       " ('President', 3),\n",
       " ('Bagheri', 3),\n",
       " ('sanctions', 3),\n",
       " ('policy', 3),\n",
       " ('Belarus', 2),\n",
       " ('sign', 2),\n",
       " ('comprehensive', 2),\n",
       " ('recent', 2),\n",
       " ('riots', 2),\n",
       " ('urges', 2),\n",
       " ('festival', 2),\n",
       " ('Top', 2),\n",
       " ('resumption', 2),\n",
       " ('Russia', 2),\n",
       " ('agree', 2),\n",
       " ('improve', 2),\n",
       " ('snooker', 2),\n",
       " ('3rd', 2),\n",
       " ('World', 2),\n",
       " ('Ceremony', 2),\n",
       " ('western', 2),\n",
       " ('5', 2),\n",
       " ('set', 2),\n",
       " ('up', 2),\n",
       " ('border', 2),\n",
       " ('15', 2),\n",
       " ('IAEA', 2),\n",
       " ('reports', 2),\n",
       " ('Tuesday', 2),\n",
       " ('Chaharshanbe', 2),\n",
       " ('increased', 2),\n",
       " ('oil', 2),\n",
       " ('Turkiye-Iran', 2),\n",
       " ('approaches', 2),\n",
       " ('Jan', 2),\n",
       " ('26', 2),\n",
       " ('fire', 2),\n",
       " ('Spox.', 2),\n",
       " ('drills', 2),\n",
       " ('Oman', 2),\n",
       " ('peace,', 2),\n",
       " ('development', 2),\n",
       " ('phase', 2),\n",
       " ('inaugurated', 2),\n",
       " ('soon', 2),\n",
       " ('terms', 2),\n",
       " ('No', 2),\n",
       " ('best', 2),\n",
       " ('resume', 2),\n",
       " ('Saudi-Iran', 2),\n",
       " ('from', 2),\n",
       " ('strategic', 2),\n",
       " ('issues', 2),\n",
       " ('Pakistan', 2),\n",
       " ('world', 2),\n",
       " ('Parliament', 2),\n",
       " ('terrorism', 2),\n",
       " ('day', 2),\n",
       " ('naval', 2),\n",
       " ('Festival', 2),\n",
       " ('role', 2),\n",
       " ('Yemen', 2),\n",
       " ('targets', 2),\n",
       " ('phone', 2),\n",
       " ('commander', 2),\n",
       " ('visits', 2),\n",
       " ('2nd', 2),\n",
       " ('growing', 2),\n",
       " ('status', 2),\n",
       " ('anti-Iran', 2),\n",
       " ('PM', 2),\n",
       " ('Bandar', 2),\n",
       " ('Shamkhani', 2),\n",
       " ('inaugurates', 2),\n",
       " ('two', 2),\n",
       " ('deal', 2),\n",
       " ('Austria', 2),\n",
       " ('Shiraz', 2),\n",
       " ('19', 2),\n",
       " ('result', 2),\n",
       " ('slams', 2),\n",
       " ('counterpart', 2),\n",
       " ('northern', 2),\n",
       " ('region', 2),\n",
       " ('Abadan', 2),\n",
       " ('SNSC', 2),\n",
       " ('Iranians', 2),\n",
       " ('hours', 2),\n",
       " ('share', 2),\n",
       " ('National', 2),\n",
       " ('speaker', 2),\n",
       " ('congratulates', 2),\n",
       " ('should', 2),\n",
       " ('1402,', 2),\n",
       " (\"'inflation\", 2),\n",
       " (\"production'\", 2),\n",
       " (':', 2),\n",
       " ('sustainable', 2),\n",
       " ('foreign', 2),\n",
       " ('Spox', 2),\n",
       " ('is', 2),\n",
       " ('towards', 2),\n",
       " ('Zionist', 2),\n",
       " ('Kharrazi', 2),\n",
       " ('Broadening', 2),\n",
       " ('countries', 2),\n",
       " ('war', 2),\n",
       " ('tourism', 2),\n",
       " ('continuation', 2),\n",
       " ('beginning', 2),\n",
       " (\"gov't\", 2),\n",
       " ('reciting', 2),\n",
       " ('Quran', 2),\n",
       " ('Gulf', 2),\n",
       " ('islands', 2),\n",
       " ('general', 2),\n",
       " ('French', 2),\n",
       " ('attractions', 2),\n",
       " ('protests', 2),\n",
       " ('historical', 2),\n",
       " ('Iraqi', 2),\n",
       " ('positive', 2),\n",
       " ('roadmap', 1),\n",
       " ('Pres.', 1),\n",
       " ('Raisi:', 1),\n",
       " ('Tehran,', 1),\n",
       " ('Minsk', 1),\n",
       " ('resolved', 1),\n",
       " ('bolster', 1),\n",
       " ('22k', 1),\n",
       " ('prisoners', 1),\n",
       " ('related', 1),\n",
       " ('pardoned', 1),\n",
       " ('sanctioned', 1),\n",
       " ('cooperate', 1),\n",
       " ('neutralize', 1),\n",
       " ('pressures', 1),\n",
       " ('arrests', 1),\n",
       " ('sabotage', 1),\n",
       " ('teams', 1),\n",
       " ('eve', 1),\n",
       " ('Kuwaiti', 1),\n",
       " ('VP', 1),\n",
       " ('determined', 1),\n",
       " ('expand', 1),\n",
       " ('diplomatic', 1),\n",
       " ('resolve', 1),\n",
       " ('banking', 1),\n",
       " ('issues:', 1),\n",
       " ('Economy', 1),\n",
       " ('minister', 1),\n",
       " ('14', 1),\n",
       " ('seeking', 1),\n",
       " ('exchanges', 1),\n",
       " ('Afghan', 1),\n",
       " ('min.', 1),\n",
       " ('player', 1),\n",
       " ('place', 1),\n",
       " ('6-Red', 1),\n",
       " ('Championship', 1),\n",
       " (\"Martyr's\", 1),\n",
       " ('Day', 1),\n",
       " ('Snow', 1),\n",
       " ('city', 1),\n",
       " ('fest', 1),\n",
       " ('‘IRGC', 1),\n",
       " ('speedboats', 1),\n",
       " ('become', 1),\n",
       " ('multiple', 1),\n",
       " ('times', 1),\n",
       " ('faster', 1),\n",
       " ('than', 1),\n",
       " ('models’', 1),\n",
       " ('Prominent', 1),\n",
       " ('poet', 1),\n",
       " ('Mohabbat,', 1),\n",
       " ('known', 1),\n",
       " ('“Two', 1),\n",
       " ('Pines”,', 1),\n",
       " ('dies', 1),\n",
       " ('80', 1),\n",
       " ('Consular', 1),\n",
       " ('services', 1),\n",
       " ('available', 1),\n",
       " ('million', 1),\n",
       " ('diaspora:', 1),\n",
       " ('Diplomat', 1),\n",
       " ('Horse', 1),\n",
       " ('show', 1),\n",
       " ('jumping', 1),\n",
       " ('University', 1),\n",
       " ('branch', 1),\n",
       " ('Georgia', 1),\n",
       " ('Relations', 1),\n",
       " ('must', 1),\n",
       " ('influenced', 1),\n",
       " ('Kurdistan', 1),\n",
       " (\"region's\", 1),\n",
       " ('events', 1),\n",
       " ('hold', 1),\n",
       " ('indicated', 1),\n",
       " ('fully', 1),\n",
       " ('abided', 1),\n",
       " ('commitments:', 1),\n",
       " ('AEOI', 1),\n",
       " ('Last', 1),\n",
       " ('the', 1),\n",
       " ('year;', 1),\n",
       " ('Soori', 1),\n",
       " ('OPEC', 1),\n",
       " ('output', 1),\n",
       " ('February', 1),\n",
       " ('$500m', 1),\n",
       " ('$500mln', 1),\n",
       " ('dead,', 1),\n",
       " ('4,360', 1),\n",
       " ('injured', 1),\n",
       " ('year-end', 1),\n",
       " ('Internal', 1),\n",
       " ('crises', 1),\n",
       " ('destroy', 1),\n",
       " ('Israel’s', 1),\n",
       " ('shaky', 1),\n",
       " ('foundations:', 1),\n",
       " ('Traditional', 1),\n",
       " ('ritual', 1),\n",
       " ('Suri', 1),\n",
       " ('Navasar', 1),\n",
       " ('village', 1),\n",
       " ('due', 1),\n",
       " ('“fine', 1),\n",
       " ('example”', 1),\n",
       " ('dialog', 1),\n",
       " ('solution:', 1),\n",
       " ('Beijing', 1),\n",
       " ('China,', 1),\n",
       " ('starting', 1),\n",
       " ('joint', 1),\n",
       " ('Sea', 1),\n",
       " ('Haghdadi', 1),\n",
       " ('appointed', 1),\n",
       " ('head', 1),\n",
       " ('Gymnastics', 1),\n",
       " ('federation', 1),\n",
       " ('No-Usti', 1),\n",
       " ('tradition', 1),\n",
       " ('NE', 1),\n",
       " ('spox:', 1),\n",
       " ('Islam', 1),\n",
       " ('brings', 1),\n",
       " ('friendship', 1),\n",
       " ('humanity', 1),\n",
       " ('refinery', 1),\n",
       " ('increase', 1),\n",
       " ('next', 1),\n",
       " ('year:', 1),\n",
       " ('Minister', 1),\n",
       " ('preserving', 1),\n",
       " ('identity', 1),\n",
       " ('significant', 1),\n",
       " ('limits', 1),\n",
       " ('expanding', 1),\n",
       " ('China:', 1),\n",
       " ('Iran-Sri', 1),\n",
       " ('Lanka', 1),\n",
       " ('‘Chabahar', 1),\n",
       " ('one', 1),\n",
       " ('locations', 1),\n",
       " ('investment’', 1),\n",
       " ('Folklore', 1),\n",
       " ('concert', 1),\n",
       " ('Rahim', 1),\n",
       " ('Shahriari', 1),\n",
       " ('16', 1),\n",
       " ('Turkmenistan,', 1),\n",
       " ('traffic', 1),\n",
       " ('Bajgiran', 1),\n",
       " ('crossing', 1),\n",
       " ('‘Iraqi', 1),\n",
       " ('initiative', 1),\n",
       " ('mediation', 1),\n",
       " ('comes', 1),\n",
       " ('Martyr', 1),\n",
       " ('Soleimani’s', 1),\n",
       " ('view’', 1),\n",
       " ('Afghanistan-Iran', 1),\n",
       " ('expand:', 1),\n",
       " ('Aramgah', 1),\n",
       " ('short', 1),\n",
       " ('film', 1),\n",
       " ('awarded', 1),\n",
       " ('IFVA', 1),\n",
       " ('admin.', 1),\n",
       " ('keen', 1),\n",
       " ('establish', 1),\n",
       " ('‘strong', 1),\n",
       " ('region’:', 1),\n",
       " ('most', 1),\n",
       " ('advanced', 1),\n",
       " ('cancer', 1),\n",
       " ('treatment', 1),\n",
       " ('center', 1),\n",
       " ('reacts', 1),\n",
       " ('Sweden’s', 1),\n",
       " ('statement', 1),\n",
       " ('Tehran’s', 1),\n",
       " ('dealing', 1),\n",
       " ('terrorist', 1),\n",
       " ('ringleader', 1),\n",
       " ('Shamkhani,', 1),\n",
       " ('Abu', 1),\n",
       " ('Dhabi', 1),\n",
       " ('Amir', 1),\n",
       " ('Sarkhosh', 1),\n",
       " ('bags', 1),\n",
       " ('championship', 1),\n",
       " ('Asian', 1),\n",
       " ('send', 1),\n",
       " ('soon:', 1),\n",
       " ('Deputy', 1),\n",
       " ('Emir', 1),\n",
       " ('Dubai', 1),\n",
       " ('promises', 1),\n",
       " ('solve', 1),\n",
       " ('citizens,', 1),\n",
       " (\"foundations'\", 1),\n",
       " ('problems', 1),\n",
       " ('Combination', 1),\n",
       " ('Security', 1),\n",
       " ('Belt', 1),\n",
       " ('Wargame', 1),\n",
       " ('kicks', 1),\n",
       " ('off', 1),\n",
       " ('Tehran-IAEA', 1),\n",
       " ('relations', 1),\n",
       " ('right', 1),\n",
       " ('path:', 1),\n",
       " ('Mission', 1),\n",
       " (\"president's\", 1),\n",
       " ('Harvesting', 1),\n",
       " ('daffodil,', 1),\n",
       " ('iris', 1),\n",
       " ('flowers', 1),\n",
       " ('SW', 1),\n",
       " ('Shrine', 1),\n",
       " ('Public', 1),\n",
       " ('opinion', 1),\n",
       " ('fed', 1),\n",
       " ('double', 1),\n",
       " ('standards:', 1),\n",
       " ('European', 1),\n",
       " ('turned', 1),\n",
       " ('into', 1),\n",
       " ('venue', 1),\n",
       " ('Iranophobic', 1),\n",
       " ('claims:', 1),\n",
       " ('Norouz', 1),\n",
       " ('trip', 1),\n",
       " ('Isfahan', 1),\n",
       " ('difference', 1),\n",
       " ('among', 1),\n",
       " ('officials:', 1),\n",
       " ('Amirabdollahian', 1),\n",
       " ('focused', 1),\n",
       " ('combating', 1),\n",
       " ('drills:', 1),\n",
       " ('Cmdr.', 1),\n",
       " ('Boldaji', 1),\n",
       " ('Confections', 1),\n",
       " ('2', 1),\n",
       " ('movies', 1),\n",
       " ('Lift-Off', 1),\n",
       " ('Film', 1),\n",
       " ('60', 1),\n",
       " ('highlight', 1),\n",
       " ('religions', 1),\n",
       " ('promoting', 1),\n",
       " ('balancing', 1),\n",
       " ('strategy', 1),\n",
       " ('advisor’s', 1),\n",
       " ('trips', 1),\n",
       " ('envoy:', 1),\n",
       " ('accord', 1),\n",
       " ('opportunity', 1),\n",
       " ('stabilize', 1),\n",
       " ('Anti-Iran', 1),\n",
       " ('hype', 1),\n",
       " ('Austrian', 1),\n",
       " ('media', 1),\n",
       " ('slammed', 1),\n",
       " ('Chinese,', 1),\n",
       " ('Russian,', 1),\n",
       " ('navies', 1),\n",
       " ('marine', 1),\n",
       " ('Turkiye', 1),\n",
       " ('IRGC', 1),\n",
       " ('Quds', 1),\n",
       " ('Force', 1),\n",
       " ('quake-stricken', 1),\n",
       " ('regions', 1),\n",
       " ('time', 1),\n",
       " ('Beijing-brokered', 1),\n",
       " ('detente', 1),\n",
       " ('proof', 1),\n",
       " (\"China's\", 1),\n",
       " ('Mideast', 1),\n",
       " ('Shameful', 1),\n",
       " ('manipulated', 1),\n",
       " ('Alinejad:', 1),\n",
       " ('Embassy', 1),\n",
       " ('Dutch', 1),\n",
       " ('18', 1),\n",
       " ('governor', 1),\n",
       " ('calls', 1),\n",
       " ('Pakistan,', 1),\n",
       " ('Fishmongers', 1),\n",
       " ('Torkaman', 1),\n",
       " ('Diplomatic', 1),\n",
       " ('diplomacy', 1),\n",
       " ('drive', 1),\n",
       " ('major', 1),\n",
       " ('subway', 1),\n",
       " ('projects', 1),\n",
       " ('launches', 1),\n",
       " ('homemade', 1),\n",
       " ('landing', 1),\n",
       " ('craft', 1),\n",
       " ('vessels', 1),\n",
       " ('Abbas', 1),\n",
       " ('can', 1),\n",
       " ('foster', 1),\n",
       " ('spokesman', 1),\n",
       " ('celebrated', 1),\n",
       " ('Stock', 1),\n",
       " ('flower', 1),\n",
       " ('sentences', 1),\n",
       " ('people', 1),\n",
       " ('death', 1),\n",
       " ('terror', 1),\n",
       " ('shrine', 1),\n",
       " ('Grand', 1),\n",
       " ('Bazaar', 1),\n",
       " ('prior', 1),\n",
       " ('holidays', 1),\n",
       " ('Haft', 1),\n",
       " ('Seen', 1),\n",
       " ('table', 1),\n",
       " ('draws', 1),\n",
       " ('Spanish', 1),\n",
       " ('royal’s', 1),\n",
       " ('attention', 1),\n",
       " ('rapprochement', 1),\n",
       " ('Raisi’s', 1),\n",
       " ('China', 1),\n",
       " ('visit:', 1),\n",
       " ('France’s', 1),\n",
       " ('lack', 1),\n",
       " ('commitment', 1),\n",
       " ('full', 1),\n",
       " ('implementation', 1),\n",
       " ('meet', 1),\n",
       " ('and', 1),\n",
       " ('pact', 1),\n",
       " ('king', 1),\n",
       " ('invites', 1),\n",
       " ('Riyadh:', 1),\n",
       " ('Senior', 1),\n",
       " ('Spring', 1),\n",
       " ('nature', 1),\n",
       " (\"Turkiye's\", 1),\n",
       " ('ambassador', 1),\n",
       " ('facilitate', 1),\n",
       " ('investments', 1),\n",
       " ('energy', 1),\n",
       " ('Iran-Iraq', 1),\n",
       " ('ensure', 1),\n",
       " ('security:', 1),\n",
       " ('gold,', 1),\n",
       " ('silver', 1),\n",
       " ('medals', 1),\n",
       " ('body', 1),\n",
       " ('builders', 1),\n",
       " ('Muscle', 1),\n",
       " ('Beach', 1),\n",
       " ('Competitions', 1),\n",
       " ('Local', 1),\n",
       " ('tournament', 1),\n",
       " ('Kurdish', 1),\n",
       " ('increases', 1),\n",
       " ('monthly', 1),\n",
       " ('minimum', 1),\n",
       " ('wage', 1),\n",
       " ('27%', 1),\n",
       " ('Refinery’s', 1),\n",
       " ('second', 1),\n",
       " ('Launch', 1),\n",
       " ('expansion', 1),\n",
       " ('project', 1),\n",
       " ('Refinery', 1),\n",
       " ('payment', 1),\n",
       " ('mechanism', 1),\n",
       " ('arrears:', 1),\n",
       " ('chief', 1),\n",
       " ('COVID-19', 1),\n",
       " ('kills', 1),\n",
       " ('more', 1),\n",
       " ('past', 1),\n",
       " ('24', 1),\n",
       " ('ready', 1),\n",
       " ('scientific', 1),\n",
       " ('achievements', 1),\n",
       " ('Assembly', 1),\n",
       " ('Human', 1),\n",
       " ('Rights', 1),\n",
       " ('Council', 1),\n",
       " ('take', 1),\n",
       " ('distance', 1),\n",
       " ('politicization:', 1),\n",
       " (\"year's\", 1),\n",
       " ('slogan', 1),\n",
       " ('inflation', 1),\n",
       " ('production', 1),\n",
       " (\"Gov't\", 1),\n",
       " ('main', 1),\n",
       " ('plan', 1),\n",
       " ('control', 1),\n",
       " ('inflation,', 1),\n",
       " ('gain', 1),\n",
       " ('Various', 1),\n",
       " ('felicitate', 1),\n",
       " ('Enmity', 1),\n",
       " ('unchangeable', 1),\n",
       " (\"regime's\", 1),\n",
       " ('policy:', 1),\n",
       " ('coming', 1),\n",
       " ('FM:', 1),\n",
       " ('harbinger', 1),\n",
       " ('hope', 1),\n",
       " ('Ali', 1),\n",
       " ('Kani', 1),\n",
       " ('depart', 1),\n",
       " ('Armenia', 1),\n",
       " ('today', 1),\n",
       " ('governance,', 1),\n",
       " ('way', 1),\n",
       " ('strong', 1),\n",
       " (\"revolution's\", 1),\n",
       " ('step:', 1),\n",
       " ('(AS)', 1),\n",
       " ('pilgrims', 1),\n",
       " ('eager', 1),\n",
       " ('meeting', 1),\n",
       " ('denies', 1),\n",
       " ('any', 1),\n",
       " ('involvement', 1),\n",
       " ('Ukraine', 1),\n",
       " ('war:', 1),\n",
       " ('Enemies', 1),\n",
       " ('points', 1),\n",
       " ('strength,', 1),\n",
       " ('weaknesses:', 1),\n",
       " (\"minister's\", 1),\n",
       " ('racist', 1),\n",
       " ('comments', 1),\n",
       " ('Kamal', 1),\n",
       " ('Assad', 1),\n",
       " ('\\xa0will', 1),\n",
       " ('lead', 1),\n",
       " ('EU,', 1),\n",
       " ('British', 1),\n",
       " ('Plots', 1),\n",
       " ('nipped', 1),\n",
       " ('bud:', 1),\n",
       " ('exchange', 1),\n",
       " ('POWs', 1),\n",
       " ('Resumption', 1),\n",
       " ('benefit', 1),\n",
       " ('region:', 1),\n",
       " ('Kuwait', 1),\n",
       " ('mutual', 1),\n",
       " ('ties,', 1),\n",
       " ('Syria', 1),\n",
       " ('hails', 1),\n",
       " ('support', 1),\n",
       " ('fighting', 1),\n",
       " ('N', 1),\n",
       " ('qualified', 1),\n",
       " ('speak', 1),\n",
       " ('Earthquake', 1),\n",
       " ('jolts', 1),\n",
       " ('heads', 1),\n",
       " ('Australian', 1),\n",
       " ('stress', 1),\n",
       " ('diplomacy,', 1),\n",
       " ('dialogue', 1),\n",
       " ('Andranik', 1),\n",
       " ('Teymourian', 1),\n",
       " ('selected', 1),\n",
       " ('coach', 1),\n",
       " ('Neighborhood', 1),\n",
       " ('means', 1),\n",
       " ('firm', 1),\n",
       " ('promoter', 1),\n",
       " ('Official', 1),\n",
       " ('sports', 1),\n",
       " ('pride', 1),\n",
       " ('Year:', 1),\n",
       " ('beach', 1),\n",
       " ('rise', 1),\n",
       " ('Cup', 1),\n",
       " ('Tomorrow,', 1),\n",
       " ('Thursday,', 1),\n",
       " ('blessed', 1),\n",
       " ('month:', 1),\n",
       " ('S.', 1),\n",
       " (\"Leader's\", 1),\n",
       " ('Office', 1),\n",
       " ('counterparts', 1),\n",
       " ('imprisoned', 1),\n",
       " ('Turkey', 1),\n",
       " ('returned', 1),\n",
       " ('Croatian', 1),\n",
       " ('nation,', 1),\n",
       " ('neighbors,', 1),\n",
       " ('priority:', 1),\n",
       " ('Kani,', 1),\n",
       " ('E3', 1),\n",
       " ('parties', 1),\n",
       " ('held', 1),\n",
       " ('Oslo', 1),\n",
       " ('thanks', 1),\n",
       " ('hosting', 1),\n",
       " ('lift', 1),\n",
       " ('opposes', 1),\n",
       " ('Ukraine,', 1),\n",
       " ('attend', 1),\n",
       " ('ceremony', 1),\n",
       " ('Golestan', 1),\n",
       " ('Palace', 1),\n",
       " ('3', 1),\n",
       " ('inseparable', 1),\n",
       " ('Lebanese', 1),\n",
       " ('Hezbollah', 1),\n",
       " ('secretary', 1),\n",
       " (\"west's\", 1),\n",
       " ('double-standards', 1),\n",
       " ('about', 1),\n",
       " ('unrests', 1),\n",
       " ('Obvious', 1),\n",
       " ('brutality,', 1),\n",
       " ('systematic', 1),\n",
       " ('Islamophobia', 1),\n",
       " ('west:', 1),\n",
       " ('Foreign', 1),\n",
       " ('Ayatollah', 1),\n",
       " ('Khamenei', 1),\n",
       " ('director', 1),\n",
       " ('touches', 1),\n",
       " ('progress', 1),\n",
       " ('regime', 1),\n",
       " ('Aleppo', 1),\n",
       " (\"Int'l\", 1),\n",
       " ('Airport', 1),\n",
       " ('FM,', 1),\n",
       " ('Qatar', 1),\n",
       " ('Iran-Russia', 1),\n",
       " ('friendly', 1),\n",
       " ('ends', 1),\n",
       " ('1-1', 1),\n",
       " ('5.6-magnitude', 1),\n",
       " ('quake', 1),\n",
       " ('strikes', 1),\n",
       " ('northwestern', 1),\n",
       " ('listen', 1),\n",
       " (\"nation's\", 1),\n",
       " ('voice', 1),\n",
       " ('instead', 1),\n",
       " ('instigating', 1),\n",
       " ('Tourist', 1),\n",
       " ('Kerman', 1),\n",
       " ('tourists', 1),\n",
       " ('Persepolis', 1),\n",
       " ('latest', 1),\n",
       " ('removal', 1),\n",
       " ('repression', 1),\n",
       " ('peaceful', 1),\n",
       " ('France', 1),\n",
       " ('Greater', 1),\n",
       " ('knowledge-based', 1),\n",
       " ('companies', 1),\n",
       " ('digging', 1),\n",
       " ('wells', 1),\n",
       " ('this', 1),\n",
       " ('Unilateral', 1),\n",
       " ('coercive', 1),\n",
       " ('measures', 1),\n",
       " ('prevent', 1),\n",
       " ('achieving', 1),\n",
       " ('objectives:', 1),\n",
       " ('People', 1),\n",
       " ('sites', 1),\n",
       " ('during', 1),\n",
       " ('analyst', 1),\n",
       " ('fruitful', 1),\n",
       " ('Baghdad', 1),\n",
       " ('Not', 1),\n",
       " ('surprising', 1),\n",
       " ('UK,', 1),\n",
       " ('Israeli', 1),\n",
       " ('regimes', 1),\n",
       " ('angry', 1),\n",
       " ('events:', 1),\n",
       " ('Tourists', 1),\n",
       " ('tomb', 1),\n",
       " ('Ferdowsi', 1),\n",
       " ('northeast', 1),\n",
       " ('Shushtar', 1),\n",
       " ('hydraulic', 1),\n",
       " ('system', 1),\n",
       " ('southwest', 1),\n",
       " ('questions', 1),\n",
       " (\"West's\", 1),\n",
       " ('feminist', 1),\n",
       " ('ministers', 1),\n",
       " ('', 1),\n",
       " ('Botanical', 1),\n",
       " ('Garden', 1),\n",
       " ('Kyrgyz', 1),\n",
       " ('Kordestan', 1),\n",
       " ('tourist', 1),\n",
       " ('spox', 1),\n",
       " ('warns', 1),\n",
       " ('against', 1),\n",
       " ('bases', 1),\n",
       " ('created', 1),\n",
       " ('request', 1),\n",
       " ('Govt', 1),\n",
       " ('Naaz', 1),\n",
       " ('Bahrain', 1),\n",
       " ('ties:', 1),\n",
       " ('Sputnik', 1),\n",
       " ('experts', 1),\n",
       " ('believe', 1),\n",
       " ('will', 1),\n",
       " ('bring', 1),\n",
       " ('consequences', 1),\n",
       " ('denounces', 1),\n",
       " ('civilian', 1),\n",
       " ('Syria’s', 1),\n",
       " ('Deir', 1),\n",
       " ('ez-Zour', 1)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2ff3b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
