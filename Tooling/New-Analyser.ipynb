{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a4e3e55",
   "metadata": {},
   "source": [
    "# Analyse server stored data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c2734784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "import time\n",
    "from collections import Counter\n",
    "import random\n",
    "\n",
    "from pymongo.mongo_client import MongoClient\n",
    "from pymongo.server_api import ServerApi\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from src.media import Outlet, Article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e402d4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions\n",
    "def getDateRange(start_date, end_date):  # Return list of datetime.date objects between start_date and end_date (inclusive).\n",
    "    date_list = []\n",
    "    curr_date = start_date\n",
    "    while curr_date <= end_date:\n",
    "        date_list.append(curr_date)\n",
    "        curr_date += timedelta(days=1)\n",
    "    return date_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6644714f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make maptlotlib show graphs in new window\n",
    "%matplotlib qt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2968257f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "# Date range for articles being scraped from the server\n",
    "startScrapeDate = \"15/09/2021\"\n",
    "endScrapeDate = \"15/09/2022\"\n",
    "\n",
    "collectionCap = -1 # The maximum amount of articles to get pulled from the server (set to -1 for uncaped scraping)\n",
    "\n",
    "startScrapeDate = datetime.strptime(startScrapeDate, \"%d/%m/%Y\")\n",
    "endScrapeDate = datetime.strptime(endScrapeDate, \"%d/%m/%Y\")\n",
    "stopwordsSet = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1c58a7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load setup data\n",
    "with open(\"./settings.json\", \"r\") as setupFile:\n",
    "    setupData = json.load(setupFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8591f4fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Collected article number 288177\n",
      " Collected a total of 288177 articles in 87.939 seconds\n"
     ]
    }
   ],
   "source": [
    "articleList = []\n",
    "startScanTime = time.time() # Track the time elapsed \n",
    "DBClient = MongoClient(setupData[\"DB_URI\"], server_api = ServerApi('1')) # Connect to the database\n",
    "\n",
    "# Get articles from DBClient\n",
    "articleCollection = DBClient[setupData[\"DB_NAME\"]]['newsData']\n",
    "articleCursor = articleCollection.aggregate([{'$match': {'publishDate': {\n",
    "                '$gt': startScrapeDate, \n",
    "                '$lt': endScrapeDate\n",
    "        }}}])\n",
    "\n",
    "for articleIndex, article in enumerate(articleCursor):\n",
    "    articleList.append(Article(\n",
    "                article[\"outletName\"],\n",
    "                article[\"headline\"],\n",
    "                article[\"description\"],\n",
    "                article[\"author\"],\n",
    "                article[\"publishDate\"],\n",
    "                article[\"sentimentScore\"]\n",
    "        ))\n",
    "    \n",
    "    print(f\"\\r Collected article number {articleIndex + 1}\", end=\"\")\n",
    "print(f\"\\n Collected a total of {len(articleList)} articles in {round((time.time() - startScanTime), 3)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1deb0684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29 outlets in total\n"
     ]
    }
   ],
   "source": [
    "# Sort articles by outlet\n",
    "outletList = []\n",
    "\n",
    "for articleIndex, article in enumerate(articleList):\n",
    "    foundOutlet = False # If the outlet has been found within `outletList`\n",
    "    for outlet in outletList:\n",
    "        if outlet.name == article.outlet:\n",
    "            outlet.addArticle(article)\n",
    "            foundOutlet = True\n",
    "            break\n",
    "    if not foundOutlet: # Make new outlet\n",
    "        newOutlet = Outlet(article.outlet)\n",
    "        outletList.append(newOutlet)    \n",
    "print(f\"Found {len(outletList)} outlets in total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "45e1f138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ABC News ===\n",
      "Published a total of 17638 articles\n",
      "Has an average sentiment of -0.089\n",
      "\n",
      "\n",
      "=== 9 News ===\n",
      "Published a total of 8415 articles\n",
      "Has an average sentiment of -0.159\n",
      "\n",
      "\n",
      "=== Sydney Morning Herald ===\n",
      "Published a total of 26608 articles\n",
      "Has an average sentiment of -0.023\n",
      "\n",
      "\n",
      "=== SBS Australia ===\n",
      "Published a total of 2277 articles\n",
      "Has an average sentiment of -0.085\n",
      "\n",
      "\n",
      "=== Independent Australia ===\n",
      "Published a total of 1203 articles\n",
      "Has an average sentiment of -0.097\n",
      "\n",
      "\n",
      "=== Daily Telegraph ===\n",
      "Published a total of 3176 articles\n",
      "Has an average sentiment of -0.089\n",
      "\n",
      "\n",
      "=== The Age ===\n",
      "Published a total of 26587 articles\n",
      "Has an average sentiment of -0.022\n",
      "\n",
      "\n",
      "=== Michael West ===\n",
      "Published a total of 1087 articles\n",
      "Has an average sentiment of -0.007\n",
      "\n",
      "\n",
      "=== The Guardian ===\n",
      "Published a total of 40154 articles\n",
      "Has an average sentiment of -0.063\n",
      "\n",
      "\n",
      "=== Crikey ===\n",
      "Published a total of 2664 articles\n",
      "Has an average sentiment of -0.04\n",
      "\n",
      "\n",
      "=== CNN ===\n",
      "Published a total of 13550 articles\n",
      "Has an average sentiment of -0.101\n",
      "\n",
      "\n",
      "=== New York Times ===\n",
      "Published a total of 5530 articles\n",
      "Has an average sentiment of -0.156\n",
      "\n",
      "\n",
      "=== Fox News ===\n",
      "Published a total of 8229 articles\n",
      "Has an average sentiment of -0.124\n",
      "\n",
      "\n",
      "=== Reuters ===\n",
      "Published a total of 9 articles\n",
      "Has an average sentiment of -0.183\n",
      "\n",
      "\n",
      "=== BBC News ===\n",
      "Published a total of 4824 articles\n",
      "Has an average sentiment of -0.227\n",
      "\n",
      "\n",
      "=== The Conversation ===\n",
      "Published a total of 2659 articles\n",
      "Has an average sentiment of 0.005\n",
      "\n",
      "\n",
      "=== The Washington Post ===\n",
      "Published a total of 4587 articles\n",
      "Has an average sentiment of -0.22\n",
      "\n",
      "\n",
      "=== Wall Street Journal ===\n",
      "Published a total of 1393 articles\n",
      "Has an average sentiment of -0.16\n",
      "\n",
      "\n",
      "=== CNBC ===\n",
      "Published a total of 4077 articles\n",
      "Has an average sentiment of -0.047\n",
      "\n",
      "\n",
      "=== Daily Mail ===\n",
      "Published a total of 39765 articles\n",
      "Has an average sentiment of -0.193\n",
      "\n",
      "\n",
      "=== Huffington Post ===\n",
      "Published a total of 10593 articles\n",
      "Has an average sentiment of -0.079\n",
      "\n",
      "\n",
      "=== BuzzFeed ===\n",
      "Published a total of 14727 articles\n",
      "Has an average sentiment of 0.111\n",
      "\n",
      "\n",
      "=== Amercian ABC ===\n",
      "Published a total of 5075 articles\n",
      "Has an average sentiment of -0.188\n",
      "\n",
      "\n",
      "=== The Economist ===\n",
      "Published a total of 6 articles\n",
      "Has an average sentiment of 0.0\n",
      "\n",
      "\n",
      "=== Sky News ===\n",
      "Published a total of 2342 articles\n",
      "Has an average sentiment of -0.245\n",
      "\n",
      "\n",
      "=== CBS News ===\n",
      "Published a total of 13608 articles\n",
      "Has an average sentiment of -0.074\n",
      "\n",
      "\n",
      "=== Alja Zeera ===\n",
      "Published a total of 7665 articles\n",
      "Has an average sentiment of -0.168\n",
      "\n",
      "\n",
      "=== USA Today ===\n",
      "Published a total of 6892 articles\n",
      "Has an average sentiment of -0.08\n",
      "\n",
      "\n",
      "=== South China Morning Post ===\n",
      "Published a total of 12808 articles\n",
      "Has an average sentiment of -0.122\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Text outputs\n",
    "for outlet in outletList:\n",
    "    # Get the average sentiment\n",
    "    avgSentiment = sum(list(article.sentimentScore for article in outlet.articleList)) / len(outlet.articleList)\n",
    "    avgSentiment = avgSentiment \n",
    "        \n",
    "    print(f\"{'=' * 3} {outlet.name} {'=' * 3}\")\n",
    "    print(f\"Published a total of {len(outlet.articleList)} articles\")\n",
    "    print(f\"Has an average sentiment of {round(avgSentiment, 3)}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a25483a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display parameters\n",
    "topicList = [['shooting', 'gun', 'control', 'uvalde', 'buffalo', 'shooter', 'gunman']] # Which topics to use (leave blank for all) (MUST BE LOWERCASE)\n",
    "showOutletsList = [] # Which outlets to be shown (leave blank for all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b2e9d031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect data to plot\n",
    "plotArticles = {} # Stores the articles by the topic \n",
    "if topicList == []:\n",
    "    plotArticles['total'] = [] # If there are no topic, total is used to show the total amt of articles\n",
    "    for article in articleList:\n",
    "        if article.outlet in showOutletsList or showOutletsList == []:\n",
    "            plotArticles['total'].append(article)\n",
    "else:            \n",
    "    for topic in topicList: \n",
    "        plotArticles[topic[0]] = [] # Each topic stores corresponding articles in a list\n",
    "        for article in articleList:\n",
    "            if article.outlet in showOutletsList or showOutletsList == []: # If the article is from the specified outlet\n",
    "                for word in article.headline.split(\" \"):\n",
    "                    if word.lower() in topic: # If a given word from the article is in the topic searchlist\n",
    "                        plotArticles[topic[0]].append(article)\n",
    "                        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2daff92f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In total, 5382 articles got published about shooting\n"
     ]
    }
   ],
   "source": [
    "# Plot daily average (or total output) for any attribute over time, as a total/avg of all outlets\n",
    "plotAttribute = \"publishCount\" # The article attribute to be avg'd and plotted over time (set to `publishCount` for daily TOTAL output)\n",
    "plotDates = getDateRange(startScrapeDate, endScrapeDate)\n",
    "\n",
    "for topic in plotArticles.keys():\n",
    "    plotData = {}\n",
    "    for dateIndex, date in enumerate(plotDates):\n",
    "        if dateIndex + 1 != len(plotDates):\n",
    "            plotData[date] = []\n",
    "    for article in plotArticles[topic]:\n",
    "        articleDate = article.date\n",
    "        if plotAttribute == \"publishCount\":\n",
    "            plotData[articleDate.replace(hour=0, minute=0, second=0)].append(1)\n",
    "        else:\n",
    "            plotData[articleDate.replace(hour=0, minute=0, second=0)].append(getattr(article, plotAttribute))\n",
    "    \n",
    "    # Plot the data\n",
    "    xVals = list(plotData.keys())\n",
    "    yVals = []\n",
    "    for val in xVals:\n",
    "        try:\n",
    "            if plotAttribute == \"publishCount\":\n",
    "                yVals.append(len(plotData[val]))\n",
    "            else:\n",
    "                yVals.append(sum(plotData[val]) / len(plotData[val]))\n",
    "        except ZeroDivisionError:\n",
    "            yVals.append(0)\n",
    "    if plotAttribute == \"publishCount\":\n",
    "        print(f\"In total, {sum(yVals)} articles got published about {topic}\")\n",
    "    plt.plot(xVals, yVals, label=topic)\n",
    "    \n",
    "plt.title(f\"{plotAttribute} Over time\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1ee6dc85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In total, BuzzFeed published 2 articles about anthony\n",
      "In total, Sydney Morning Herald published 81 articles about anthony\n",
      "In total, The Guardian published 136 articles about anthony\n",
      "In total, CNN published 3 articles about anthony\n",
      "In total, CBS News published 3 articles about anthony\n",
      "In total, ABC News published 71 articles about anthony\n",
      "In total, 9 News published 28 articles about anthony\n",
      "In total, Crikey published 53 articles about anthony\n",
      "In total, Fox News published 0 articles about anthony\n",
      "In total, Huffington Post published 5 articles about anthony\n",
      "In total, Independent Australia published 7 articles about anthony\n",
      "In total, Daily Telegraph published 11 articles about anthony\n",
      "In total, The Age published 79 articles about anthony\n",
      "In total, Michael West published 12 articles about anthony\n",
      "In total, BBC News published 4 articles about anthony\n",
      "In total, The Conversation published 47 articles about anthony\n",
      "In total, Wall Street Journal published 1 articles about anthony\n",
      "In total, Amercian ABC published 3 articles about anthony\n",
      "In total, Sky News published 1 articles about anthony\n",
      "In total, Alja Zeera published 4 articles about anthony\n",
      "In total, USA Today published 1 articles about anthony\n",
      "In total, South China Morning Post published 11 articles about anthony\n",
      "In total, New York Times published 4 articles about anthony\n",
      "In total, The Washington Post published 1 articles about anthony\n",
      "In total, Daily Mail published 177 articles about anthony\n",
      "In total, CNBC published 4 articles about anthony\n",
      "In total, BuzzFeed published 0 articles about scot\n",
      "In total, Sydney Morning Herald published 46 articles about scot\n",
      "In total, The Guardian published 100 articles about scot\n",
      "In total, CNN published 0 articles about scot\n",
      "In total, CBS News published 0 articles about scot\n",
      "In total, ABC News published 44 articles about scot\n",
      "In total, 9 News published 21 articles about scot\n",
      "In total, Crikey published 42 articles about scot\n",
      "In total, Fox News published 8 articles about scot\n",
      "In total, Huffington Post published 3 articles about scot\n",
      "In total, Independent Australia published 13 articles about scot\n",
      "In total, Daily Telegraph published 3 articles about scot\n",
      "In total, The Age published 45 articles about scot\n",
      "In total, Michael West published 5 articles about scot\n",
      "In total, BBC News published 2 articles about scot\n",
      "In total, The Conversation published 17 articles about scot\n",
      "In total, Wall Street Journal published 0 articles about scot\n",
      "In total, Amercian ABC published 0 articles about scot\n",
      "In total, Sky News published 4 articles about scot\n",
      "In total, Alja Zeera published 0 articles about scot\n",
      "In total, USA Today published 0 articles about scot\n",
      "In total, South China Morning Post published 7 articles about scot\n",
      "In total, New York Times published 1 articles about scot\n",
      "In total, The Washington Post published 2 articles about scot\n",
      "In total, Daily Mail published 143 articles about scot\n",
      "In total, CNBC published 0 articles about scot\n"
     ]
    }
   ],
   "source": [
    "# Plot any attribute over time but broken down by outlet\n",
    "plotAttribute = \"publishCount\" # The article attribute to be avg'd and plotted over time (set to `publishCount` for daily TOTAL output)\n",
    "plotDates = getDateRange(startScrapeDate, endScrapeDate) # A list of all the dates that will be plotted\n",
    "\n",
    "displayOutlets = [] # The list that keeps track of which outlets to display\n",
    "if showOutletsList == []: # If the user has not specified which outlets to show, show all of them\n",
    "    for outlet in outletList:\n",
    "        displayOutlets.append(outlet.name) \n",
    "else:\n",
    "    displayOutlets = showOutletsList # Else show only those specified\n",
    "\n",
    "for topic in plotArticles.keys():\n",
    "    for outlet in displayOutlets: # Show how each media outlet reports each topic\n",
    "        plotData = {} # Dict containing each display date as key, and the list of scores for that day as value\n",
    "        for dateIndex, date in enumerate(plotDates):\n",
    "            if dateIndex + 1 != len(plotDates):\n",
    "                plotData[date] = []\n",
    "                \n",
    "        for article in plotArticles[topic]:\n",
    "            if article.outlet == outlet:\n",
    "                articleDate = article.date\n",
    "                if plotAttribute == \"publishCount\": # If the user is trying to find how many articles have been published on a given day, add 1 per article\n",
    "                    plotData[articleDate.replace(hour=0, minute=0, second=0)].append(1)\n",
    "                else:\n",
    "                    plotData[articleDate.replace(hour=0, minute=0, second=0)].append(getattr(article, plotAttribute)) # Append the score to the daily list\n",
    "        \n",
    "        # Plot the data\n",
    "        xVals = list(plotData.keys())\n",
    "        yVals = []\n",
    "        for val in xVals:\n",
    "            try:\n",
    "                if plotAttribute == \"publishCount\":\n",
    "                    yVals.append(len(plotData[val])) # Plot the daily count (total)\n",
    "                else:\n",
    "                    yVals.append(sum(plotData[val]) / len(plotData[val])) # plot the daily average \n",
    "            except ZeroDivisionError:\n",
    "                yVals.append(0) # If there are no datapoints for the day, display 0\n",
    "        plt.plot(xVals, yVals, label=f\"{outlet} - {topic}\")\n",
    "        \n",
    "        if plotAttribute == \"publishCount\":\n",
    "            print(f\"In total, {outlet} published {sum(yVals)} articles about {topic}\")\n",
    "plt.title(f\"{plotAttribute} Over time by Outlet\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bd2cbb24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Find keywords for each day by topic\n",
    "dailyDisplay = 4 # The number of keywords that gets displayed for each date\n",
    "displayTopic = \"shooting\" # The topic that gets graphed\n",
    "minTextScore = 2 # The minimum number of a times a keyword needs to be mentioned in order to get it's text displayed\n",
    "try:\n",
    "    plotArticles[displayTopic]\n",
    "except KeyError:\n",
    "    print(f\"Topic {displayTopic} is not available, the possible topics are {list(plotArticles.keys())}\")\n",
    "    \n",
    "\n",
    "keywordColors = {} # Dict containing the color for each keyword\n",
    "plotDates = getDateRange(startScrapeDate, endScrapeDate) # A list of all the dates that will be plotted\n",
    "\n",
    "datedKeywords = {} # A dict containg all the keywords in articles from a given date about the topic\n",
    "for dateIndex, date in enumerate(plotDates):\n",
    "    if dateIndex + 1 != len(plotDates):\n",
    "        datedKeywords[date] = []\n",
    "\n",
    "for article in plotArticles[displayTopic]:\n",
    "    if article.outlet in showOutletsList or showOutletsList == []: # If the article is from the specified outlet\n",
    "        articleDate = article.date\n",
    "        for word in article.headline.split(\" \"):\n",
    "            word = word.strip().lower()\n",
    "            if word not in stopwordsSet and len(word) > 2:\n",
    "                datedKeywords[articleDate.replace(hour=0, minute=0, second=0)].append(lemmatizer.lemmatize(word)) # Append the (lemmatized) word to the dict for the given date\n",
    "\n",
    "lastKeywords = []\n",
    "for date in datedKeywords.keys():\n",
    "    keywords = Counter(datedKeywords[date]).most_common(dailyDisplay)\n",
    "    for keyword in keywords:\n",
    "        try:\n",
    "            keywordColor = keywordColors[keyword[0]] # If the keyword already has a color for itself\n",
    "        except KeyError:\n",
    "            r = lambda: random.randint(0,255) # Else, generate a new color for the keyword\n",
    "            keywordColor = '#%02X%02X%02X' % (r(),r(),r())\n",
    "            keywordColors[keyword[0]] = keywordColor # If this is the first time \n",
    "\n",
    "\n",
    "        plt.scatter(date, keyword[1], color=keywordColor, label=keyword[0]) # Put the point on the graph\n",
    "\n",
    "        # Draw lines between points with the same keyword\n",
    "        foundPrior = False # Tracks whether the date before contains the same keyword\n",
    "        for lastKeyword in lastKeywords:\n",
    "            if lastKeyword[0] == keyword[0]:\n",
    "                plt.plot([lastDate, date], [lastKeyword[1], keyword[1]], color=keywordColor)\n",
    "                foundPrior = True\n",
    "                break\n",
    "\n",
    "        if not foundPrior and keyword[1] >= minTextScore: # Only display text if the point is at the start of a 'chain'\n",
    "            plt.text(date, keyword[1], keyword[0])\n",
    "\n",
    "    # Save the last date and keywords to plot lines in the next date\n",
    "    lastDate = date \n",
    "    lastKeywords = keywords\n",
    "\n",
    "plt.title(f\"Keywords over time for topic {displayTopic}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3dbdd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
