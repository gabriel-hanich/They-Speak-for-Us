{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5db8a476",
   "metadata": {},
   "source": [
    "# Analyse data stored in the server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07d955be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "import csv\n",
    "\n",
    "from pymongo.mongo_client import MongoClient\n",
    "from pymongo.server_api import ServerApi\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.media import Article, Outlet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "959b8713",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70ae2ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "# What dates to get from DB\n",
    "startScanDate = \"15/09/2021\"\n",
    "endScanDate = \"12/09/2022\"\n",
    "\n",
    "collectionCap = -1 # The max amount of articles collected from the DB (set to -1 for uncapped collection)\n",
    "\n",
    "startScanDate = datetime.strptime(startScanDate, \"%d/%m/%Y\")\n",
    "endScanDate = datetime.strptime(endScanDate, \"%d/%m/%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97f1e5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions\n",
    "def getDateRange(start_date, end_date):\n",
    "    # Return list of datetime.date objects between start_date and end_date (inclusive).\n",
    "    date_list = []\n",
    "    curr_date = start_date\n",
    "    while curr_date <= end_date:\n",
    "        date_list.append(curr_date)\n",
    "        curr_date += timedelta(days=1)\n",
    "    return date_list\n",
    "\n",
    "def getDailyAverages(articleList, value) -> dict:\n",
    "    dayData = {}\n",
    "    \n",
    "    # Make a dict containing each date \n",
    "    sortList = articleList.copy()\n",
    "    sortList.sort(key=lambda x: x.date)\n",
    "    for date in getDateRange(sortList[0].date, sortList[-1].date):\n",
    "        dayData[date.replace(hour=0, minute=0, second=0)] = {\"count\": 0, \"total\": 0}\n",
    "    \n",
    "    # Get the total score for each date \n",
    "    for article in articleList:\n",
    "        try:\n",
    "            dayData[article.date.replace(hour=0, minute=0, second=0)][\"total\"] += getattr(article, value)\n",
    "            dayData[article.date.replace(hour=0, minute=0, second=0)][\"count\"] += 1\n",
    "        except KeyError as e:\n",
    "            pass\n",
    "    # Calculate average for each day\n",
    "    for date in dayData.keys():\n",
    "        try:\n",
    "            dayData[date] = dayData[date][\"total\"] / dayData[date][\"count\"]\n",
    "        except ZeroDivisionError:\n",
    "            dayData[date] = 0\n",
    "    return dayData\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b4a976c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./settings.json\", \"r\") as setupFile:\n",
    "    setupData = json.load(setupFile) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2413b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Scan\n",
      " Collecting article number 261660"
     ]
    }
   ],
   "source": [
    "# Read data from MongoDB\n",
    "articleList = []\n",
    "DBClient = MongoClient(setupData[\"DB_URI\"], server_api=ServerApi('1')) # Connect to DB\n",
    "\n",
    "outletCollection = DBClient[setupData[\"DB_NAME\"]]['newsData']\n",
    "outletCursor = outletCollection.find({})\n",
    "print(\"Starting Scan\")\n",
    "\n",
    "for documentIndex, document in enumerate(outletCursor):\n",
    "    try:\n",
    "        # If the article is from the correct time period\n",
    "        if document[\"publishDate\"] > startScanDate and document[\"publishDate\"] < endScanDate:\n",
    "            articleList.append(Article(\n",
    "                document[\"outletName\"],\n",
    "                document[\"headline\"],\n",
    "                document[\"description\"],\n",
    "                document[\"author\"],\n",
    "                document[\"publishDate\"],\n",
    "                document[\"sentimentScore\"]\n",
    "            ))\n",
    "            print(f\"\\r Collecting article number {len(articleList)}\", end=\"\")\n",
    "        \n",
    "        # Stop collecting articles if the cap is reached\n",
    "        if collectionCap != -1 and len(articleList) >= collectionCap: \n",
    "            break\n",
    "    # If an article is missing a data point, it is discarded\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "print(f\"\\nCollected {len(articleList)} Articles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b06fc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "outletList = []\n",
    "print(\"Sorting articles\")\n",
    "for articleIndex, article in enumerate(articleList):\n",
    "    foundOutlet = False\n",
    "    for outlet in outletList:\n",
    "        if outlet.name == article.outlet:\n",
    "            outlet.addArticle(article)\n",
    "            foundOutlet = True\n",
    "            break\n",
    "    if not foundOutlet:\n",
    "        newOutlet = Outlet(article.outlet)\n",
    "        newOutlet.addArticle(article)\n",
    "        outletList.append(newOutlet)\n",
    "outletList.sort(key=lambda x: len(x.articleList), reverse=True)\n",
    "print(f\"Done sorting, {len(outletList)} outlets found\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989e4264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out basic stats\n",
    "for outlet in outletList:\n",
    "    # Gather data\n",
    "    authorList = []\n",
    "    avgSentiment = 0\n",
    "    for article in outlet.articleList:\n",
    "        if article.author not in authorList:\n",
    "            authorList.append(article.author)\n",
    "        avgSentiment += article.sentimentScore / len(outlet.articleList)\n",
    "        \n",
    "    print(f\"{'=' * 3} {outlet.name} {'=' * 3}\")\n",
    "    print(f\"Published a total of {len(outlet.articleList)} articles\")\n",
    "    print(f\"Has an average sentiment of {round(avgSentiment, 3)}\")\n",
    "    print(f\"And has had articles from {len(authorList)} different authors\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f6a8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort into topics \n",
    "topicList = [[\"Joe\", \"Biden\", \"Democrat\", \"Democrats\"], [\"Donald\", \"Trump\"]] \n",
    "for topicIndex, topic in enumerate(topicList):\n",
    "    topicData = {\"topicName\": topic[0], \"outletList\": []}\n",
    "    articleCount = 0\n",
    "    for outlet in outletList:\n",
    "        thisOutlet = Outlet(outlet.name)\n",
    "        for article in outlet.articleList:\n",
    "            for searchWord in topic:\n",
    "                if searchWord in article.headline.split(\" \"):\n",
    "                    thisOutlet.addArticle(article)\n",
    "                    articleCount += 1\n",
    "                    break\n",
    "        \n",
    "        topicData[\"outletList\"].append(thisOutlet)\n",
    "    print(f\"Topic '{topic[0]}' has {articleCount} articles about it\")\n",
    "    topicList[topicIndex] = topicData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc981b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot specific trait against the other\n",
    "trait1 = \"puvb\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0946bc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output total data into a .csv file\n",
    "outletIndexes = {}\n",
    "for outletIndex, outlet in enumerate(outletList):\n",
    "    outletIndexes[outlet.name] = outletIndex \n",
    "\n",
    "outletNames = list(outlet.name for outlet in outletList)\n",
    "outletNames.insert(0, \"\")\n",
    "\n",
    "dailySentiment = {}\n",
    "dailyOutput = {}\n",
    "for date in getDateRange(startScanDate, endScanDate):\n",
    "    dailySentiment[date] = list(0 for i in range(len(outletList)))\n",
    "    dailyOutput[date]  = list(0 for i in range(len(outletList)))\n",
    "\n",
    "for outlet in outletList:\n",
    "    # Get daily sentiment\n",
    "    sentimentVals = getDailyAverages(outlet.articleList, \"sentimentScore\")\n",
    "    for date in sentimentVals.keys():\n",
    "        dailySentiment[date][outletIndexes[outlet.name]] = sentimentVals[date]\n",
    "    \n",
    "    # Get daily output\n",
    "    for article in outlet.articleList:\n",
    "        articleDate = article.date\n",
    "        dailyOutput[articleDate.replace(hour=0, minute=0, second=0)][outletIndexes[outlet.name]] += 1\n",
    "\n",
    "\n",
    "    \n",
    "with open(\"data/dailyAvgSentiment.csv\", \"w+\", encoding='UTF8', newline='') as sentimentOutput:\n",
    "    writer = csv.writer(sentimentOutput)\n",
    "    writer.writerow(outletNames)\n",
    "    for date in dailySentiment.keys():\n",
    "        dateRow = dailySentiment[date]\n",
    "        dateRow.insert(0, date.strftime(\"%d/%m/%Y\"))\n",
    "        writer.writerow(dateRow)\n",
    "with open(\"data/dailyOutput.csv\", \"w+\", encoding='UTF8', newline='') as outputFile:\n",
    "    writer = csv.writer(outputFile)\n",
    "    writer.writerow(outletNames)\n",
    "    for date in dailyOutput.keys():\n",
    "        dateRow = dailyOutput[date]\n",
    "        dateRow.insert(0, date.strftime(\"%d/%m/%Y\"))\n",
    "        writer.writerow(dateRow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5be9b429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output topic specific data\n",
    "topicIndexes = {}\n",
    "for topicIndex, topic in enumerate(topicList):\n",
    "    topicIndexes[topic[\"topicName\"]] = topicIndex\n",
    "topicNames = list(topic[\"topicName\"] for topic in topicList)\n",
    "topicNames.insert(0, \"\")\n",
    "\n",
    "dailySentiment = {}\n",
    "dailyOutput = {}\n",
    "for date in getDateRange(startScanDate, endScanDate):\n",
    "    dailySentiment[date] = list(0 for i in range(len(topicList)))\n",
    "    dailyOutput[date] = list(0 for i in range(len(topicList)))\n",
    "    \n",
    "for topic in topicList:\n",
    "    # Get list containing all published articles AND get the number of published articles each day\n",
    "    articleList = []\n",
    "    for outlet in topic[\"outletList\"]:\n",
    "        for article in outlet.articleList:\n",
    "            articleList.append(article)\n",
    "            articleDate = article.date\n",
    "            dailyOutput[articleDate.replace(hour=0, minute=0, second=0)][topicIndexes[topic[\"topicName\"]]] += 1\n",
    "            \n",
    "    # Get daily sentiment\n",
    "    sentimentVals = getDailyAverages(articleList, \"sentimentScore\")\n",
    "    for date in sentimentVals.keys():\n",
    "        dailySentiment[date][topicIndexes[topic[\"topicName\"]]]= sentimentVals[date]\n",
    "    \n",
    "\n",
    "with open(\"./data/topicAvgDailySentiment.csv\", \"w+\", encoding=\"UTF-8\", newline = \"\") as sentimentFile:\n",
    "    writer = csv.writer(sentimentFile)\n",
    "    writer.writerow(topicNames)\n",
    "    for date in dailySentiment.keys():\n",
    "        dateRow = dailySentiment[date]\n",
    "        dateRow.insert(0, date.strftime(\"%d/%m/%Y\"))\n",
    "        writer.writerow(dateRow)\n",
    "        \n",
    "with open(\"./data/topicDailyOutput.csv\", \"w+\", encoding=\"UTF-8\", newline = \"\") as outputFile:\n",
    "    writer = csv.writer(outputFile)\n",
    "    writer.writerow(topicNames)\n",
    "    for date in dailyOutput.keys():\n",
    "        dateRow = dailyOutput[date]\n",
    "        dateRow.insert(0, date.strftime(\"%d/%m/%Y\"))\n",
    "        writer.writerow(dateRow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86882fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
